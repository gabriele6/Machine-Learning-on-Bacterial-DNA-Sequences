{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUaRpbATSlhM",
        "outputId": "d78859ad-83ef-4eca-d234-b57ee3dbf55f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwjFxxAvdGq-"
      },
      "source": [
        "## VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrsnujaGx8u_"
      },
      "outputs": [],
      "source": [
        "BASE_PATH = '/content/drive/MyDrive/Health/'\n",
        "DATASET_PATH = BASE_PATH + 'dataset/'\n",
        "VOCAB_PATH = '/content/drive/MyDrive/Health/vocab.txt'\n",
        "\n",
        "TEST_SET_PATH = BASE_PATH + 'test_1000-1099.fas'\n",
        "\n",
        "K = 6\n",
        "SPLIT_SIZE = 3584 #100*671"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wim9JJYW563e"
      },
      "source": [
        "# DNA BERT\n",
        "\n",
        "[github link](https://github.com/jerryji1993/DNABERT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNNsUVIh7fgR"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3ke8rbkRUy0"
      },
      "source": [
        "### BioPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLxG1iUPRTWu",
        "outputId": "aea02e3d-2a7b-4138-a6b0-d9fff2c3ec1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Bio\n",
            "  Downloading bio-1.3.8-py3-none-any.whl (269 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 153 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 163 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 174 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 184 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 194 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 269 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Collecting mygene\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.64.0)\n",
            "Collecting biopython>=1.79\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.6)\n",
            "Collecting biothings-client>=0.2.6\n",
            "  Downloading biothings_client-0.2.6-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2021.10.8)\n",
            "Installing collected packages: biothings-client, mygene, biopython, Bio\n",
            "Successfully installed Bio-1.3.8 biopython-1.79 biothings-client-0.2.6 mygene-3.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install Bio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts9SxkeDRY6o"
      },
      "source": [
        "### DNA Bert Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qJ4pJQh585v",
        "outputId": "3a013e1a-f811-4438-ac15-1b01aac8a587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'DNABERT'...\n",
            "remote: Enumerating objects: 766, done.\u001b[K\n",
            "remote: Total 766 (delta 0), reused 0 (delta 0), pack-reused 766\u001b[K\n",
            "Receiving objects: 100% (766/766), 11.60 MiB | 11.20 MiB/s, done.\n",
            "Resolving deltas: 100% (403/403), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jerryji1993/DNABERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2uWn0r96NRG",
        "outputId": "3ba04e88-3d08-4d30-d3c4-029fcec62e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DNABERT\n",
            "Obtaining file:///content/DNABERT\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (1.21.6)\n",
            "Collecting tokenizers==0.5.0\n",
            "  Downloading tokenizers-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 8.7 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.23.2-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 42.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting botocore<1.27.0,>=1.26.2\n",
            "  Downloading botocore-1.26.2-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.0,>=1.26.2->boto3->transformers==2.5.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.2->boto3->transformers==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.0) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=0cd31f3cc9de7f6e917626a26271f0e36158484a9f5f76954ae9c1fa7e950cc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Running setup.py develop for transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.23.2 botocore-1.26.2 jmespath-1.0.0 s3transfer-0.5.2 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.5.0 transformers-2.5.0 urllib3-1.25.11\n",
            "/content/DNABERT/examples\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.0.2)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.10.2)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.79)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.3.5)\n",
            "Collecting pybedtools\n",
            "  Downloading pybedtools-0.9.0.tar.gz (12.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.5 MB 19.9 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->-r requirements.txt (line 3)) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (1.46.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 2)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 2)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 2)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 2)) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->-r requirements.txt (line 7)) (0.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 9)) (2022.1)\n",
            "Collecting pysam\n",
            "  Downloading pysam-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.0 MB 2.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: seqeval, pybedtools\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=fab4ebc6a9089e4b9b099ba9aeecc51942939e011b90f4be1a965e59931ca924\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for pybedtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybedtools: filename=pybedtools-0.9.0-cp37-cp37m-linux_x86_64.whl size=13616813 sha256=015db5946e4825c8a59f2927abd31f950ee1d15f0d6ba54ccead2f6cbf2e992f\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/44/0d/3a7449885adaf8ebb157da8c3c834a712f48b3b3b84ba51dda\n",
            "Successfully built seqeval pybedtools\n",
            "Installing collected packages: pysam, tensorboardX, seqeval, sentencepiece, pybedtools, pyahocorasick\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.96\n",
            "    Uninstalling sentencepiece-0.1.96:\n",
            "      Successfully uninstalled sentencepiece-0.1.96\n",
            "Successfully installed pyahocorasick-1.4.4 pybedtools-0.9.0 pysam-0.19.0 sentencepiece-0.1.91 seqeval-1.2.2 tensorboardX-2.5\n"
          ]
        }
      ],
      "source": [
        "%cd DNABERT\n",
        "!pip install --editable .\n",
        "%cd examples\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTBfVKafSBt_"
      },
      "source": [
        "## Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOw-ypR-SAzu"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "from itertools import product\n",
        "import random\n",
        "import glob\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2tzAYak7idO"
      },
      "source": [
        "## Vocab Building\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXcPgGrXCIpN"
      },
      "outputs": [],
      "source": [
        "# lst = [\"A\", \"C\", \"G\", \"T\", \"-\"]\n",
        "lst = [\"A\", \"C\", \"G\", \"T\"]\n",
        "lengthOfStrings = 6\n",
        "prod = product(lst, repeat=lengthOfStrings)\n",
        "n_prod = 0\n",
        "vocab = []\n",
        "with open(VOCAB_PATH, 'w') as f:\n",
        "  f.write('[PAD]\\n[UNK]\\n[CLS]\\n[SEP]\\n[MASK]\\n')\n",
        "  for i in prod:\n",
        "    string = ''\n",
        "    for letter in i:\n",
        "      string += letter\n",
        "    f.write(string + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkX2lfYSUGH"
      },
      "source": [
        "## Sequences to Kmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRkF6XAOXDM_"
      },
      "outputs": [],
      "source": [
        "def seq2kmer(seq, k, clean=True):\n",
        "  if clean:\n",
        "    seq = seq.replace('-','')\n",
        "  kmer = [seq[x:x+k] for x in range(len(seq)+1-k)]\n",
        "  kmers = \" \".join(kmer)\n",
        "  return kmers\n",
        "\n",
        "def getLength(file_path):\n",
        "  ctr = 0\n",
        "  seq = SeqIO.parse(open(file_path),'fasta')\n",
        "  for el in seq: ctr+=1\n",
        "  return ctr\n",
        "\n",
        "def getRandom():\n",
        "  return random.uniform(0,1)\n",
        "\n",
        "def seq2chars(seq, k, clean=True):\n",
        "  if clean:\n",
        "    seq = seq.replace('-','')\n",
        "  mini_seq = ''\n",
        "  for x in range(len(seq)):\n",
        "    if x != 0 and x % k == 0:\n",
        "      mini_seq += ' '\n",
        "    mini_seq += seq[x]\n",
        "          \n",
        "  return mini_seq\n",
        "\n",
        "# seq= '-----------G----GT---GTGATGGGGASACAJKSNCJSC'\n",
        "# print(seq2kmer(seq, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpoof8dAjwSe"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Idl03PREH-a"
      },
      "outputs": [],
      "source": [
        "!mkdir dataset\n",
        "!mkdir output\n",
        "!mkdir temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FJwnXCPCbvJ"
      },
      "source": [
        "### Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emMXEclFCd0Z"
      },
      "outputs": [],
      "source": [
        "RATIO = 0.8\n",
        "CARRIER_LABEL = 0\n",
        "MENING_LABEL = 1\n",
        "\n",
        "def getLabel(seq_header):\n",
        "  label = CARRIER_LABEL\n",
        "  if 'meningitis' in seq_header:\n",
        "    label = MENING_LABEL\n",
        "  return label\n",
        "\n",
        "def buildTrainingSet(path, ratio=0.8):\n",
        "  sequences = []\n",
        "  for filename in glob.glob(path + 'ms_*.fas'):\n",
        "    print(filename)\n",
        "    with open(filename) as ms_in:\n",
        "      sequences += ms_in.readlines()\n",
        "\n",
        "  for filename in glob.glob(path + 'c_*.fas'):\n",
        "    print(filename)\n",
        "    with open(filename) as ms_in:\n",
        "      sequences += ms_in.readlines()\n",
        "\n",
        "  with open('dataset.fas', 'w') as seq_file:\n",
        "    seq_file.write(''.join(sequences))\n",
        "\n",
        "  parsed_seq = SeqIO.parse(open('dataset.fas'),'fasta')\n",
        "  train_ctr = 0\n",
        "  dev_ctr = 0 \n",
        "\n",
        "  os.makedirs('./temp/', exist_ok=True)\n",
        "  with open('./temp/train.tsv', 'w') as train_file:\n",
        "    with open('./temp/dev.tsv', 'w') as dev_file:\n",
        "      train_file.write('sequence\\tlabel\\n')\n",
        "      dev_file.write('sequence\\tlabel\\n')\n",
        "\n",
        "      for seq_record in parsed_seq:\n",
        "        label = 0\n",
        "        if 'meningitis' in seq_record.id:\n",
        "          label = 1\n",
        "        kmered = seq2kmer(str(seq_record.seq), K)\n",
        "        if kmered:\n",
        "          if getRandom() < ratio:\n",
        "            train_file.write(kmered + '\\t' + str(label) + '\\n')\n",
        "            train_ctr += 1\n",
        "          else:\n",
        "            dev_file.write(kmered + '\\t' + str(label) + '\\n')\n",
        "            dev_ctr += 1\n",
        "      print('TOTAL: ' + str(train_ctr + dev_ctr))\n",
        "      print('\\t Train: ' + str(train_ctr))\n",
        "      print('\\t Dev: ' + str(dev_ctr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn0w8movFbqa",
        "outputId": "d7338c93-2612-465e-9f89-f31271b86198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Health/dataset/ms_001-299.fas\n",
            "/content/drive/MyDrive/Health/dataset/ms_300-599.fas\n",
            "/content/drive/MyDrive/Health/dataset/ms_600-899.fas\n",
            "/content/drive/MyDrive/Health/dataset/c_001-299.fas\n",
            "/content/drive/MyDrive/Health/dataset/c_300-599.fas\n",
            "/content/drive/MyDrive/Health/dataset/c_600-899.fas\n",
            "TOTAL: 1779\n",
            "\t Train: 1418\n",
            "\t Dev: 361\n"
          ]
        }
      ],
      "source": [
        "buildTrainingSet(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zom4QTybF_Q1"
      },
      "outputs": [],
      "source": [
        "!cp temp/* /content/drive/MyDrive/Health/dataset/temp/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soz2yFNPe-hy"
      },
      "source": [
        "### OLD Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGeUJMS0sphj",
        "outputId": "2e332531-d600-4d92-9d68-5b09eca831d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Health/dataset/ms_001-299.fas\n",
            "/content/drive/MyDrive/Health/dataset/ms_300-599.fas\n",
            "/content/drive/MyDrive/Health/dataset/ms_600-899.fas\n",
            "/content/drive/MyDrive/Health/dataset/c_001-299.fas\n",
            "/content/drive/MyDrive/Health/dataset/c_300-599.fas\n",
            "/content/drive/MyDrive/Health/dataset/c_600-899.fas\n"
          ]
        }
      ],
      "source": [
        "# Open ms_data in write mode\n",
        "with open('ms_data.fas', 'w') as outfile:\n",
        "  filenames = glob.glob(DATASET_PATH + 'ms_*.fas')\n",
        "  for names in filenames:\n",
        "    print(names)\n",
        "    with open(names) as infile:\n",
        "      outfile.write(infile.read())\n",
        "    # outfile.write(\"\\n\")\n",
        "\n",
        "with open('c_data.fas', 'w') as outfile:\n",
        "  filenames = glob.glob(DATASET_PATH + 'c_*.fas')\n",
        "  for names in filenames:\n",
        "    print(names)\n",
        "    with open(names) as infile:\n",
        "      outfile.write(infile.read())\n",
        "    # outfile.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOWvwUo0wwq2",
        "outputId": "451a01e8-31a9-4135-8500-d9e25cef3c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "810\n"
          ]
        }
      ],
      "source": [
        "# mening_sequences = SeqIO.parse(open('ms_data.fas'),'fasta')\n",
        "# for seq_record in mening_sequences:\n",
        "#   print(seq_record.id.split('|')[1])\n",
        "  # print(repr(seq_record.seq))\n",
        "  # print(len(seq_record))\n",
        "  \n",
        "def getLength(file_path):\n",
        "  ctr = 0\n",
        "  seq = SeqIO.parse(open(file_path),'fasta')\n",
        "  for el in seq: ctr+=1\n",
        "  return ctr\n",
        "\n",
        "# Writing Training and Validation sets using a 9/1 ratio\n",
        "mening_sequences = SeqIO.parse(open('ms_data.fas'),'fasta')\n",
        "carrier_sequences = SeqIO.parse(open('c_data.fas'),'fasta')\n",
        "\n",
        "DATASET_LENGTH = getLength('ms_data.fas')\n",
        "RATIO = 0.9\n",
        "LIMIT = int(RATIO*DATASET_LENGTH)\n",
        "print(LIMIT)\n",
        "\n",
        "CARRIER_LABEL = 0\n",
        "MENING_LABEL = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d_yBtcSXLu",
        "outputId": "3186292d-dc9a-4ada-ea23-c40f1aca5750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequenced 900 samples.\n"
          ]
        }
      ],
      "source": [
        "with open('./dataset/train.tsv', 'w') as t_file:\n",
        "  with open('./dataset/dev.tsv', 'w') as d_file:\n",
        "    ctr = 0\n",
        "    t_file.write('sequence\\tlabel\\n')\n",
        "    d_file.write('sequence\\tlabel\\n')\n",
        "    for seq_record in mening_sequences:\n",
        "      kmered = seq2kmer(str(seq_record.seq), K)\n",
        "      if not kmered: continue\n",
        "      if ctr < LIMIT:\n",
        "        t_file.write(kmered + '\\t' + str(MENING_LABEL) + '\\n')\n",
        "      else:\n",
        "        d_file.write(kmered + '\\t' + str(MENING_LABEL) + '\\n')\n",
        "      ctr += 1\n",
        "    \n",
        "    ctr = 0\n",
        "    for seq_record in carrier_sequences:\n",
        "      kmered = seq2kmer(str(seq_record.seq), K)\n",
        "      if not kmered: continue\n",
        "      if ctr < LIMIT:\n",
        "        t_file.write(kmered + '\\t' + str(CARRIER_LABEL) + '\\n')\n",
        "      else:\n",
        "        d_file.write(kmered + '\\t' + str(CARRIER_LABEL) + '\\n')\n",
        "      ctr += 1\n",
        "\n",
        "print('Sequenced ' + str(ctr) + ' samples.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrlMclKNUCCF"
      },
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5FGfVHhUtI1",
        "outputId": "42d7c750-eed0-4898-b1f8-7b10dfe7aa8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Health/test_1000-1099.fas\n"
          ]
        }
      ],
      "source": [
        "!ls $TEST_SET_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKZSacRiUFmx"
      },
      "outputs": [],
      "source": [
        "def buildTestSet(path):\n",
        "  test_sequences = SeqIO.parse(open(path),'fasta')\n",
        "  os.makedirs('./temp/', exist_ok=True)\n",
        "  with open('./temp/test.tsv', 'w') as test_file:\n",
        "    test_file.write('sequence\\tlabel\\n')\n",
        "    for seq_record in test_sequences:\n",
        "      kmered = seq2kmer(str(seq_record.seq), K)\n",
        "      label = 1\n",
        "      if 'carrier' in seq_record.id:\n",
        "        label = 0\n",
        "      test_file.write(kmered + '\\t' + str(label) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSm4x_THUOdn",
        "outputId": "2556c717-b467-4eae-8c07-271302299396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOTAL: 0\n",
            "\t Train: 0\n",
            "\t Dev: 0\n"
          ]
        }
      ],
      "source": [
        "buildTrainingSet(TEST_SET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLg-frQ-fBLc"
      },
      "source": [
        "### Old Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCbiYJnRTWOM"
      },
      "outputs": [],
      "source": [
        "test_sequences = SeqIO.parse(open(TEST_SET_PATH),'fasta')\n",
        "\n",
        "with open('./dataset/test.tsv', 'w') as test_file:\n",
        "  test_file.write('sequence\\tlabel\\n')\n",
        "  for seq_record in test_sequences:\n",
        "    kmered = seq2kmer(str(seq_record.seq), K)\n",
        "    label = getLabel(seq_record.id)\n",
        "    test_file.write(kmered + '\\t' + str(label) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CojumhJGHiHL"
      },
      "outputs": [],
      "source": [
        "# !cp ./dataset/test.tsv /content/drive/MyDrive/Health/dataset/test.tsv\n",
        "!cp ./temp/test.tsv /content/drive/MyDrive/Health/dataset/temp/test.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMBtbTpHolyP"
      },
      "source": [
        "### Sequences Split and Shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBxX_KGCFHcf"
      },
      "outputs": [],
      "source": [
        "filenames = ['train.tsv', 'dev.tsv', 'test.tsv']\n",
        "\n",
        "def splitLine(seq, label, split_size):\n",
        "  with open('temp/' + filename, 'r') as f:\n",
        "    with open('dataset/' + filename, 'w') as out:\n",
        "      print(filename)\n",
        "      lines = f.readlines()\n",
        "      out.write(lines[0])\n",
        "      lines = lines[1:]\n",
        "      random.shuffle(lines)\n",
        "      ctr = 0\n",
        "\n",
        "      for line in lines:\n",
        "        start_pos = 0\n",
        "        end_pos = split_size\n",
        "        line = line.split('\\t')\n",
        "        while(start_pos<=len(line[0])):\n",
        "          out.write(line[0][start_pos:end_pos] + '\\t' + str(ctr))\n",
        "          start_pos+=split_size\n",
        "          end_pos+=split_size\n",
        "        ctr += 1\n",
        "  \n",
        "\n",
        "def splitSequence(filename, split_size=SPLIT_SIZE):\n",
        "  with open('temp/' + filename, 'r') as f:\n",
        "    with open('dataset/' + filename, 'w') as out:\n",
        "      print(filename)\n",
        "      lines = f.readlines()\n",
        "      out.write(lines[0])\n",
        "      lines = lines[1:]\n",
        "      random.shuffle(lines)\n",
        "      ctr = 0\n",
        "      for line in lines:\n",
        "        if ctr != len(lines) - 1:\n",
        "          line = line.split('\\t')\n",
        "          out.write(line[0][0:split_size] + '\\t' + line[1])\n",
        "        else:\n",
        "          line = line.split('\\t')\n",
        "          out.write(line[0][0:split_size] + '\\t' + line[1].split('\\n')[0])\n",
        "        ctr += 1\n",
        "\n",
        "\n",
        "def count_lines(filename):\n",
        "  f = open(filename)                  \n",
        "  lines = 0\n",
        "  buf_size = 1024 * 1024\n",
        "  read_f = f.read # loop optimization\n",
        "\n",
        "  buf = read_f(buf_size)\n",
        "  while buf:\n",
        "      lines += buf.count('\\n')\n",
        "      buf = read_f(buf_size)\n",
        "\n",
        "  return lines\n",
        "\n",
        "def splitSeq2Lines(filename, split_size):\n",
        "  os.makedirs('./dataset/', exist_ok=True)\n",
        "  in_path = DATASET_PATH + 'temp/'  + filename\n",
        "  out_path = 'dataset/' + filename\n",
        "\n",
        "  with open(in_path, 'r') as f:\n",
        "    n_lines = count_lines(in_path)\n",
        "    print('LINES: ' + str(n_lines))\n",
        "    with open(out_path, 'w') as out:\n",
        "      print(filename)\n",
        "      \n",
        "      line = f.readline()\n",
        "      out.write('sequence\\tid\\n') # writing header\n",
        "      ctr = 0\n",
        "      while line:\n",
        "        # do stuff with line\n",
        "        line = f.readline()\n",
        "        start_pos = 0\n",
        "        end_pos = split_size\n",
        "        splitted_line = line.split('\\t')\n",
        "        while(start_pos<=len(splitted_line[0])):\n",
        "          out.write(splitted_line[0][start_pos:end_pos-1] + '\\t' + str(ctr) + '\\n')\n",
        "          start_pos+=split_size\n",
        "          end_pos+=split_size\n",
        "        ctr += 1\n",
        "        if ctr % 100 == 0: \n",
        "          print('['+filename+'] ' + str(ctr/n_lines*100) + '%\\t' + str(ctr))\n",
        "\n",
        "SPLIT_SIZE = 3584 #512 words (kmers)\n",
        "print('Split Size: ' + str(SPLIT_SIZE))\n",
        "for filename in filenames:\n",
        "  splitSeq2Lines(filename, SPLIT_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7vOayvAhF5k",
        "outputId": "481ea0aa-f17b-4703-b678-2498f32e53f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1198368"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_lines(DATASET_PATH + 'dataset_k512/train/train.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wivh1tEXglEZ",
        "outputId": "3f787270-474c-4423-bd88-848cdd28c9e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘test’: File exists\n"
          ]
        }
      ],
      "source": [
        "# copying test dataset to its oown folder and renaming it because they are stupid and didn't think about it\n",
        "!mkdir test\n",
        "!mv dataset/test.tsv test/dev.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSsKEJUBnUpR"
      },
      "outputs": [],
      "source": [
        "# !cp prova/test.tsv test/dev.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_v8041KrTiD"
      },
      "outputs": [],
      "source": [
        "# DEST_PATH = DATASET_PATH + 'dataset_300M_300C.txt'\n",
        "# !cp dataset_300M_300C.txt $DEST_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wyv19OJeb1p"
      },
      "source": [
        "### Get ID-Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufhcBtJuefQx",
        "outputId": "8b37ac25-7804-4b94-91b0-b45013b70ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dev.tsv  test.tsv  train.tsv\n"
          ]
        }
      ],
      "source": [
        "TEMP_DATASET = \"/content/drive/MyDrive/Health/dataset/temp/\"\n",
        "!ls $TEMP_DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abdV1cHyfl3W"
      },
      "outputs": [],
      "source": [
        "def generateIdLabelsFile(filename):\n",
        "  output_path = filename.split('.')[0] + '_id_labels.txt'\n",
        "  with open(TEMP_DATASET + filename, 'r') as input, open(output_path, 'w') as output:\n",
        "    n_lines = count_lines(TEMP_DATASET + filename)\n",
        "    print('[' + filename + ']LINES: ' + str(n_lines))\n",
        "    line = input.readline() #header\n",
        "    output.write('seq_id\\tlabel\\n') #write header\n",
        "    ctr = 0\n",
        "    while line:\n",
        "      line = input.readline()\n",
        "      splitted_line = line.split('\\t')\n",
        "      if len(splitted_line) < 2:\n",
        "        break\n",
        "      label = splitted_line[1]\n",
        "      seq_id = ctr\n",
        "      output.write(str(seq_id) + '\\t' + str(label))\n",
        "      ctr += 1\n",
        "      if ctr % 100 == 0: \n",
        "        print(ctr)\n",
        "  print('File saved: ' + output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWmDSKLbzdL9",
        "outputId": "2b053d37-e0eb-4054-8840-0946443dd6c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[test.tsv]LINES: 201\n",
            "100\n",
            "200\n",
            "File saved: test_id_labels.txt\n"
          ]
        }
      ],
      "source": [
        "filename = 'test.tsv'\n",
        "generateIdLabelsFile(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvwvbL8NhaYv",
        "outputId": "b7d55ee3-ae97-4993-aea0-f6410433850f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seq_id\tlabel\n",
            "0\t0\n",
            "1\t0\n",
            "2\t0\n",
            "3\t0\n",
            "4\t0\n",
            "5\t0\n",
            "6\t0\n",
            "7\t0\n",
            "8\t0\n",
            "9\t0\n",
            "10\t0\n",
            "11\t0\n",
            "12\t0\n",
            "13\t0\n",
            "14\t0\n",
            "15\t0\n",
            "16\t0\n",
            "17\t0\n",
            "18\t0\n",
            "19\t0\n",
            "20\t0\n",
            "21\t0\n",
            "\u001b[K"
          ]
        }
      ],
      "source": [
        "!more test_id_labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_xTIWL-quiy"
      },
      "outputs": [],
      "source": [
        "!mkdir emb_test\n",
        "!unzip /content/drive/MyDrive/Health/dataset/dataset_k512/embeddings/test.zip\n",
        "!mv *.pt ./emb_test/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyUV2iqRrPRb",
        "outputId": "ba83b7bc-82ed-40dd-bbde-2af6d0af9fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import torch\n",
        "\n",
        "def load_id_labels(path):\n",
        "  labels = []\n",
        "  with open(path, 'r') as input:\n",
        "    line = input.readline()\n",
        "    while line:\n",
        "      line = input.readline()\n",
        "      splitted_line = line.split('\\t')\n",
        "      if len(splitted_line) < 2:\n",
        "        break\n",
        "      seq_id = splitted_line[0]\n",
        "      label = int(splitted_line[1])\n",
        "      labels.append(label)\n",
        "\n",
        "  return labels\n",
        "\n",
        "labels = load_id_labels('test_id_labels.txt')\n",
        "print(len(labels))\n",
        "\n",
        "def getEmbeddingDataset(path):\n",
        "  embeddings = {}\n",
        "  emb_array = []\n",
        "  for filename in sorted(glob.glob(path + '/*.pt')):\n",
        "    seq_id = int(filename.split('.pt')[0].split('seq')[1])\n",
        "    if seq_id == len(labels): # erase the last one since it's empty\n",
        "      break\n",
        "    label = labels[seq_id]\n",
        "    tensors = torch.load(filename, map_location=torch.device('cpu'))\n",
        "    embeddings[seq_id] = {'label': label, \n",
        "                          'tensors': tensors\n",
        "                          }\n",
        "    emb_array.append(tensors)\n",
        "  return embeddings, emb_array\n",
        "  # print('seq[' + str(seq_id) + '] label = ' + str(label))\n",
        "\n",
        "embeddings, emb_array = getEmbeddingDataset('emb_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f8qxX6tONrQo",
        "outputId": "212d02ff-08be-4870-bf8a-d74c390de11b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b06b9b18980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0memb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memb_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'emb_array' is not defined"
          ]
        }
      ],
      "source": [
        "for emb in emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zULngJGz4Gly"
      },
      "outputs": [],
      "source": [
        "train_X = []\n",
        "train_y = []\n",
        "for i in range(len(emb_array)):\n",
        "  label = labels[i]\n",
        "  for emb in emb_array[i].values():\n",
        "    train_X.append(emb.tolist())\n",
        "    train_y.append(label)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(list(zip(train_X, train_y)),\n",
        "               columns =['X', 'y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "drAJ0uUU9cLg",
        "outputId": "e14a15d7-b05f-4934-9ea8-13348c7047c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-af26b59d-17e7-4e06-8b8a-b439d18af315\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[0.5868362188339233, -0.2806219160556793, -0.3...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[0.21693071722984314, -0.1528603583574295, 0.2...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.586708664894104, -0.2802076041698456, 0.030...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[0.25666671991348267, -0.54011070728302, 0.551...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[0.5566396713256836, -0.2230125218629837, 0.13...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af26b59d-17e7-4e06-8b8a-b439d18af315')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af26b59d-17e7-4e06-8b8a-b439d18af315 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af26b59d-17e7-4e06-8b8a-b439d18af315');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   X  y\n",
              "0  [0.5868362188339233, -0.2806219160556793, -0.3...  0\n",
              "1  [0.21693071722984314, -0.1528603583574295, 0.2...  0\n",
              "2  [0.586708664894104, -0.2802076041698456, 0.030...  0\n",
              "3  [0.25666671991348267, -0.54011070728302, 0.551...  0\n",
              "4  [0.5566396713256836, -0.2230125218629837, 0.13...  0"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFqgs0TA-zuP"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "indices = [x for x in range(768)]\n",
        "df = df['X'].transform({f'X{i+1}': itemgetter(i) for i in indices})\n",
        "df['y'] = train_y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "qz9lq69J_LJm",
        "outputId": "7949ea9d-e029-44c4-c9c5-35554f5537e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-97b4f3b5-0b35-44fb-9818-1a92bf1bd5d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>X9</th>\n",
              "      <th>X10</th>\n",
              "      <th>...</th>\n",
              "      <th>X760</th>\n",
              "      <th>X761</th>\n",
              "      <th>X762</th>\n",
              "      <th>X763</th>\n",
              "      <th>X764</th>\n",
              "      <th>X765</th>\n",
              "      <th>X766</th>\n",
              "      <th>X767</th>\n",
              "      <th>X768</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.586836</td>\n",
              "      <td>-0.280622</td>\n",
              "      <td>-0.393021</td>\n",
              "      <td>-0.006847</td>\n",
              "      <td>0.532320</td>\n",
              "      <td>0.069348</td>\n",
              "      <td>0.587181</td>\n",
              "      <td>-0.426089</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.144710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.288943</td>\n",
              "      <td>-0.177624</td>\n",
              "      <td>0.310271</td>\n",
              "      <td>-0.602017</td>\n",
              "      <td>-0.116125</td>\n",
              "      <td>-0.100209</td>\n",
              "      <td>-0.293820</td>\n",
              "      <td>0.382296</td>\n",
              "      <td>0.270869</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.216931</td>\n",
              "      <td>-0.152860</td>\n",
              "      <td>0.269706</td>\n",
              "      <td>0.317533</td>\n",
              "      <td>0.560679</td>\n",
              "      <td>-0.449366</td>\n",
              "      <td>0.103354</td>\n",
              "      <td>-0.144298</td>\n",
              "      <td>0.240491</td>\n",
              "      <td>0.313215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.218332</td>\n",
              "      <td>-0.106709</td>\n",
              "      <td>-0.782730</td>\n",
              "      <td>-0.144598</td>\n",
              "      <td>-0.387436</td>\n",
              "      <td>-0.037106</td>\n",
              "      <td>0.074231</td>\n",
              "      <td>0.504337</td>\n",
              "      <td>0.384010</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.586709</td>\n",
              "      <td>-0.280208</td>\n",
              "      <td>0.030081</td>\n",
              "      <td>-0.115715</td>\n",
              "      <td>0.466501</td>\n",
              "      <td>0.442316</td>\n",
              "      <td>-0.454067</td>\n",
              "      <td>-0.302339</td>\n",
              "      <td>-0.062956</td>\n",
              "      <td>0.206698</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.751148</td>\n",
              "      <td>0.193287</td>\n",
              "      <td>-0.677578</td>\n",
              "      <td>-0.275258</td>\n",
              "      <td>-0.447550</td>\n",
              "      <td>-0.566069</td>\n",
              "      <td>-0.354516</td>\n",
              "      <td>0.297212</td>\n",
              "      <td>0.097665</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.256667</td>\n",
              "      <td>-0.540111</td>\n",
              "      <td>0.551641</td>\n",
              "      <td>-0.362935</td>\n",
              "      <td>0.050804</td>\n",
              "      <td>-0.479595</td>\n",
              "      <td>0.234828</td>\n",
              "      <td>-0.463642</td>\n",
              "      <td>0.251334</td>\n",
              "      <td>0.516325</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.106587</td>\n",
              "      <td>0.228359</td>\n",
              "      <td>-0.533587</td>\n",
              "      <td>-0.031965</td>\n",
              "      <td>-0.422599</td>\n",
              "      <td>0.416044</td>\n",
              "      <td>0.322401</td>\n",
              "      <td>0.497008</td>\n",
              "      <td>0.092302</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.556640</td>\n",
              "      <td>-0.223013</td>\n",
              "      <td>0.138141</td>\n",
              "      <td>-0.607483</td>\n",
              "      <td>0.066755</td>\n",
              "      <td>-0.385463</td>\n",
              "      <td>0.162250</td>\n",
              "      <td>0.415066</td>\n",
              "      <td>-0.003597</td>\n",
              "      <td>-0.104311</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.032077</td>\n",
              "      <td>0.408256</td>\n",
              "      <td>-0.017650</td>\n",
              "      <td>-0.267663</td>\n",
              "      <td>-0.398181</td>\n",
              "      <td>0.408359</td>\n",
              "      <td>0.703377</td>\n",
              "      <td>0.369062</td>\n",
              "      <td>-0.052011</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 769 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97b4f3b5-0b35-44fb-9818-1a92bf1bd5d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97b4f3b5-0b35-44fb-9818-1a92bf1bd5d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97b4f3b5-0b35-44fb-9818-1a92bf1bd5d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         X1        X2        X3        X4        X5        X6        X7  \\\n",
              "0  0.586836 -0.280622 -0.393021 -0.006847  0.532320  0.069348  0.587181   \n",
              "1  0.216931 -0.152860  0.269706  0.317533  0.560679 -0.449366  0.103354   \n",
              "2  0.586709 -0.280208  0.030081 -0.115715  0.466501  0.442316 -0.454067   \n",
              "3  0.256667 -0.540111  0.551641 -0.362935  0.050804 -0.479595  0.234828   \n",
              "4  0.556640 -0.223013  0.138141 -0.607483  0.066755 -0.385463  0.162250   \n",
              "\n",
              "         X8        X9       X10  ...      X760      X761      X762      X763  \\\n",
              "0 -0.426089 -0.044642 -0.144710  ...  0.288943 -0.177624  0.310271 -0.602017   \n",
              "1 -0.144298  0.240491  0.313215  ...  0.218332 -0.106709 -0.782730 -0.144598   \n",
              "2 -0.302339 -0.062956  0.206698  ... -0.751148  0.193287 -0.677578 -0.275258   \n",
              "3 -0.463642  0.251334  0.516325  ... -0.106587  0.228359 -0.533587 -0.031965   \n",
              "4  0.415066 -0.003597 -0.104311  ... -0.032077  0.408256 -0.017650 -0.267663   \n",
              "\n",
              "       X764      X765      X766      X767      X768  y  \n",
              "0 -0.116125 -0.100209 -0.293820  0.382296  0.270869  0  \n",
              "1 -0.387436 -0.037106  0.074231  0.504337  0.384010  0  \n",
              "2 -0.447550 -0.566069 -0.354516  0.297212  0.097665  0  \n",
              "3 -0.422599  0.416044  0.322401  0.497008  0.092302  0  \n",
              "4 -0.398181  0.408359  0.703377  0.369062 -0.052011  0  \n",
              "\n",
              "[5 rows x 769 columns]"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoYPT9YDBAgc",
        "outputId": "391bd72f-7e1a-4397-b094-39793004ac96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: (31034,768)\n",
            "y: (31034,1)\n"
          ]
        }
      ],
      "source": [
        "y = df[df.columns[-1:]]\n",
        "X = df[df.columns[:-1]]\n",
        "\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "print('X: ({},{})'.format(X.shape[0], X.shape[1]))\n",
        "print('y: ({},{})'.format(y.shape[0], y.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BySqgb2BXFP"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(X)\n",
        "\n",
        "tr_X, ts_X, tr_y, ts_y = train_test_split(X, y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxDRolNv8MY-",
        "outputId": "d22a6281-0852-4600-f79c-8ab01328a0c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(tr_X,tr_y.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvCS6UrmDA91",
        "outputId": "b5ca0721-7a9c-41bf-bd25-fb22a8dfa4b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:680: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  estimator.fit(X_train, y_train, **fit_params)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[ 702 2132]\n",
            " [ 798 2575]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.25      0.32      2834\n",
            "           1       0.55      0.76      0.64      3373\n",
            "\n",
            "    accuracy                           0.53      6207\n",
            "   macro avg       0.51      0.51      0.48      6207\n",
            "weighted avg       0.51      0.53      0.49      6207\n",
            "\n",
            "\n",
            "\n",
            "=== All AUC Scores ===\n",
            "[0.43868739 0.49816939 0.50829459 0.48519542 0.49946919 0.50354878\n",
            " 0.48769667 0.4814686  0.48423051 0.50005319]\n",
            "\n",
            "\n",
            "=== Mean AUC Score ===\n",
            "Mean AUC Score - Random Forest:  0.4886813727265105\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# predictions\n",
        "rfc_predict = rfc.predict(ts_X)\n",
        "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(ts_y, rfc_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(ts_y, rfc_predict))\n",
        "print('\\n')\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxgsPX_YuZ1E"
      },
      "outputs": [],
      "source": [
        "# import tensorflow.keras.backend as K\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# from sklearn.model_selection import KFold\n",
        "\n",
        "# forest = RandomForestClassifier()\n",
        "# rf_random = RandomizedSearchCV(estimator = forest, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
        "# rf_random.fit(df.X, df.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfP1LtlVVrOq"
      },
      "source": [
        "## Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3qvauIRsPHN"
      },
      "outputs": [],
      "source": [
        "KMER = K\n",
        "MODEL_PATH=BASE_PATH + 'DNABERT6/'\n",
        "DATA_PATH='dataset'\n",
        "OUTPUT_PATH='output'\n",
        "\n",
        "EPOCHS = 5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh3Azc3htnhP",
        "outputId": "6ea894a3-718e-4dee-eded-9fcf5f22aa12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "05/09/2022 10:53:04 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/09/2022 10:53:04 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/Health/DNABERT6/config.json\n",
            "05/09/2022 10:53:04 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 10,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "05/09/2022 10:53:04 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /root/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e\n",
            "05/09/2022 10:53:04 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/Health/DNABERT6/pytorch_model.bin\n",
            "05/09/2022 10:53:07 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "05/09/2022 10:53:07 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "05/09/2022 10:53:07 - INFO - __main__ -   finish loading model\n",
            "05/09/2022 10:53:10 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='dataset', device=device(type='cuda'), do_ensemble_pred=False, do_eval=True, do_lower_case=False, do_predict=False, do_train=True, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=0.0002, local_rank=-1, logging_steps=100, max_grad_norm=1.0, max_seq_length=100, max_steps=-1, model_name_or_path='/content/drive/MyDrive/Health/DNABERT6/', model_type='dna', n_gpu=1, n_process=8, no_cuda=False, num_rnn_layer=2, num_train_epochs=5.0, output_dir='output', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_pred_batch_size=8, per_gpu_train_batch_size=32, predict_dir=None, predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=4000, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0.1, warmup_steps=0, weight_decay=0.01)\n",
            "05/09/2022 10:53:10 - INFO - __main__ -   Creating features from dataset file at dataset\n",
            "05/09/2022 10:53:10 - INFO - transformers.data.processors.glue -   LOOKING AT dataset/train.tsv\n",
            "finish loading examples\n",
            "number of processes for converting feature: 8\n",
            "1 processor started !\n",
            "2 processor started !\n",
            "3 processor started !\n",
            "4 processor started !\n",
            "5 processor started !\n",
            "6 processor started !\n",
            "7 processor started !\n",
            "8 processor started !\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/200\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 1292 2523 3749 3260 1491 2950 2629 3589 3530 1462 3461 1679 2988 2511 2788 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/200\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 138 342 2743 2981 2508 2523 3813 3260 1491 2951 2755 3781 3467 1463 3528 1679 2988 2431 2788 325 3111 4035 3135 268 3077 707 2195 1419 32 652 5 707 3627 3519 4021 467 3879 411 1413 3123 2011 3867 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/200\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-201\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 138 342 2743 2981 2508 2523 3813 3260 1491 2951 2755 3781 3467 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1419 32 652 5 707 3627 3519 4021 467 3879 411 1413 3123 2011 3867 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 181 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 1498 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-202\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 139 406 2807 2981 2508 2395 3813 3260 1491 2950 2629 3717 3530 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2960 2557 2303 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-401\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/200\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-203\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/200\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-402\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 1292 2523 3749 3260 1491 2950 2629 3589 3530 1462 3461 1679 2988 2511 2788 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-601\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-204\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2960 2557 2303 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-403\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2395 3813 3260 1491 2950 2629 3717 3530 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/200\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/200\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   Writing example 0/205\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-404\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 1498 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1001\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1201\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2395 3813 3260 1491 2950 2629 3717 3530 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1401\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1002\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 1498 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1003\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 63 268 3077 707 2195 1355 31 3724 53 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1004\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 2554 645 3267 138 342 2743 2981 2508 2523 3813 3260 1299 2950 2755 3781 3467 1463 3525 1679 2924 2430 2660 325 3111 4035 63 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1727 1718 112 1717 3548 135 2544 2055 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1461 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   guid: train-1005\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:11 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2368 3650 1407 2176 3637 70 3718 3517 1526 698 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2719 438 1475 4035 195 735 2075 2512 2547 3916 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4029 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3603 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   input_ids: 2 3130 1651 3333 3198 3653 1093 3173 4033 30 14 3599 2058 3767 1474 1605 450 1413 3941 3127 2499 195 453 3722 2024 1525 2053 3743 447 3982 147 4004 3911 2984 1691 451 1477 4035 1474 699 3003 3910 2503 697 1477 3219 4023 187 125 2037 1666 1607 693 121 2561 2562 587 3954 3381 946 3083 1721 2967 3230 2745 1405 3995 963 953 2071 3440 2999 128 118 247 23 550 232 1683 2936 1623 2239 3948 23 3078 3778 1435 3941 1213 3998 1407 22 3702 1479 246 3637 2938 3645 3918 3\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   guid: train-5\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 138 342 2743 2981 2508 2523 3813 3260 1491 2951 2755 3781 3467 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1419 32 652 5 707 3627 3519 4021 467 3879 411 1413 3123 2011 3867 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 181 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2960 2557 2303 3\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   guid: train-205\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2176 3637 70 3718 3517 1526 698 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2783 438 1475 4035 195 735 2075 2512 2547 3916 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3731 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   guid: train-801\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2176 3637 70 3718 3517 1526 650 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2719 438 1475 4035 195 735 2075 2512 2547 3980 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3731 3355 3845 3331 155 3267 1499 1623 3\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:15 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-602\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2176 3637 70 3718 3517 1526 698 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2783 438 1475 4035 195 735 2075 2512 2547 3916 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3731 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-1402\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 454 685 1499 2923 940 2464 2445 2432 3650 1471 2240 3651 191 123 3612 3151 335 3333 4023 2981 3987 11 2895 139 3408 2533 2053 3253 911 3599 3148 2997 2457 53 3310 1675 3163 4035 3975 3984 1701 1452 748 3011 514 2247 1659 3211 252 3207 3734 1719 933 426 1191 2115 794 379 3183 3676 3397 3514 1721 2053 4032 3935 3742 3778 451 3791 195 3787 399 15 3510 3749 3244 2437 3996 3141 164 4028 2987 147 3994 3731 181 4025 919 4029 953 1476 56 3975 1463 3996 1438 1159 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-1202\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2240 3637 70 3720 3769 2550 650 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2783 438 1475 4035 195 735 2075 2512 2547 3980 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3731 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-603\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 1292 2523 3749 3260 1491 2950 2629 3589 3530 1462 3461 1679 2988 2511 2788 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-405\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2176 3637 70 3718 3517 1526 698 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2719 438 1475 4035 195 735 2075 2512 2547 3980 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3603 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-802\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 1527 3919 3200 3532 1887 3765 703 3523 3798 2778 3087 3475 2060 3786 419 3838 3829 56 2294 1771 195 3455 3112 3829 1135 3136 3475 647 2560 3455 4035 3835 956 3827 3834 2239 63 443 3756 693 962 1743 3738 3083 947 2183 399 2544 347 3820 688 954 1727 2099 2892 3788 1203 4028 2928 1482 1533 659 695 2231 768 1286 3131 3088 492 3573 2119 428 2143 4023 2263 392 2668 3269 2796 3484 2741 645 3310 1468 332 2431 3914 195 3843 15 607 451 43 3717 1115 2112 2307 31 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-1203\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 1292 2523 3749 3260 1491 2950 2629 3589 3530 1462 3461 1679 2988 2511 2788 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-604\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-803\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-1204\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-605\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 3717 3267 138 342 2743 2981 2508 2395 3813 3260 1491 2950 2629 3717 3530 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-804\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-1205\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 1498 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   guid: train-805\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 53 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:16 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:53:20 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:20 - INFO - transformers.data.processors.glue -   guid: train-1403\n",
            "05/09/2022 10:53:20 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2176 3637 70 3720 3513 2550 650 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2783 438 1475 4035 195 735 2075 2512 2547 3916 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3731 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:53:20 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:20 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:20 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   guid: train-1404\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2176 3637 70 3720 3513 2550 650 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2719 438 1475 4035 195 735 2075 2512 2547 3980 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3603 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   guid: train-1405\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:53:25 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:56:48 - INFO - __main__ -   Saving features into cached file dataset/cached_train_DNABERT6_100_dnaprom\n",
            "05/09/2022 10:56:48 - INFO - __main__ -   ***** Running training *****\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Num examples = 1605\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Num Epochs = 5\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Total optimization steps = 255\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Continuing training from epoch 0\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Continuing training from global step 0\n",
            "05/09/2022 10:56:48 - INFO - __main__ -     Will skip the first 0 steps in the first epoch\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/51 [00:00<?, ?it/s]\u001b[A/content/DNABERT/src/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   2% 1/51 [00:01<00:53,  1.07s/it]\u001b[A\n",
            "Iteration:   4% 2/51 [00:02<00:50,  1.02s/it]\u001b[A\n",
            "Iteration:   6% 3/51 [00:03<00:48,  1.00s/it]\u001b[A\n",
            "Iteration:   8% 4/51 [00:03<00:46,  1.02it/s]\u001b[A\n",
            "Iteration:  10% 5/51 [00:04<00:44,  1.03it/s]\u001b[A\n",
            "Iteration:  12% 6/51 [00:05<00:43,  1.03it/s]\u001b[A\n",
            "Iteration:  14% 7/51 [00:06<00:42,  1.03it/s]\u001b[A\n",
            "Iteration:  16% 8/51 [00:07<00:41,  1.04it/s]\u001b[A\n",
            "Iteration:  18% 9/51 [00:08<00:40,  1.03it/s]\u001b[A\n",
            "Iteration:  20% 10/51 [00:09<00:39,  1.03it/s]\u001b[A\n",
            "Iteration:  22% 11/51 [00:10<00:38,  1.03it/s]\u001b[A\n",
            "Iteration:  24% 12/51 [00:11<00:37,  1.04it/s]\u001b[A\n",
            "Iteration:  25% 13/51 [00:12<00:36,  1.04it/s]\u001b[A\n",
            "Iteration:  27% 14/51 [00:13<00:35,  1.04it/s]\u001b[A\n",
            "Iteration:  29% 15/51 [00:14<00:34,  1.04it/s]\u001b[A\n",
            "Iteration:  31% 16/51 [00:15<00:33,  1.04it/s]\u001b[A\n",
            "Iteration:  33% 17/51 [00:16<00:32,  1.04it/s]\u001b[A\n",
            "Iteration:  35% 18/51 [00:17<00:31,  1.04it/s]\u001b[A\n",
            "Iteration:  37% 19/51 [00:18<00:30,  1.04it/s]\u001b[A\n",
            "Iteration:  39% 20/51 [00:19<00:29,  1.05it/s]\u001b[A\n",
            "Iteration:  41% 21/51 [00:20<00:28,  1.04it/s]\u001b[A\n",
            "Iteration:  43% 22/51 [00:21<00:27,  1.04it/s]\u001b[A\n",
            "Iteration:  45% 23/51 [00:22<00:26,  1.04it/s]\u001b[A\n",
            "Iteration:  47% 24/51 [00:23<00:25,  1.04it/s]\u001b[A\n",
            "Iteration:  49% 25/51 [00:24<00:25,  1.04it/s]\u001b[A\n",
            "Iteration:  51% 26/51 [00:25<00:24,  1.03it/s]\u001b[A\n",
            "Iteration:  53% 27/51 [00:26<00:23,  1.03it/s]\u001b[A\n",
            "Iteration:  55% 28/51 [00:27<00:22,  1.04it/s]\u001b[A\n",
            "Iteration:  57% 29/51 [00:28<00:21,  1.04it/s]\u001b[A\n",
            "Iteration:  59% 30/51 [00:29<00:20,  1.04it/s]\u001b[A\n",
            "Iteration:  61% 31/51 [00:29<00:19,  1.03it/s]\u001b[A\n",
            "Iteration:  63% 32/51 [00:30<00:18,  1.04it/s]\u001b[A\n",
            "Iteration:  65% 33/51 [00:31<00:17,  1.03it/s]\u001b[A\n",
            "Iteration:  67% 34/51 [00:32<00:16,  1.03it/s]\u001b[A\n",
            "Iteration:  69% 35/51 [00:33<00:15,  1.03it/s]\u001b[A\n",
            "Iteration:  71% 36/51 [00:34<00:14,  1.03it/s]\u001b[A\n",
            "Iteration:  73% 37/51 [00:35<00:13,  1.03it/s]\u001b[A\n",
            "Iteration:  75% 38/51 [00:36<00:12,  1.03it/s]\u001b[A\n",
            "Iteration:  76% 39/51 [00:37<00:11,  1.03it/s]\u001b[A\n",
            "Iteration:  78% 40/51 [00:38<00:10,  1.03it/s]\u001b[A\n",
            "Iteration:  80% 41/51 [00:39<00:09,  1.03it/s]\u001b[A\n",
            "Iteration:  82% 42/51 [00:40<00:08,  1.04it/s]\u001b[A\n",
            "Iteration:  84% 43/51 [00:41<00:07,  1.03it/s]\u001b[A\n",
            "Iteration:  86% 44/51 [00:42<00:06,  1.03it/s]\u001b[A\n",
            "Iteration:  88% 45/51 [00:43<00:05,  1.03it/s]\u001b[A\n",
            "Iteration:  90% 46/51 [00:44<00:04,  1.03it/s]\u001b[A\n",
            "Iteration:  92% 47/51 [00:45<00:03,  1.04it/s]\u001b[A\n",
            "Iteration:  94% 48/51 [00:46<00:02,  1.03it/s]\u001b[A\n",
            "Iteration:  96% 49/51 [00:47<00:01,  1.04it/s]\u001b[A\n",
            "Iteration:  98% 50/51 [00:48<00:00,  1.04it/s]\u001b[A\n",
            "Iteration: 100% 51/51 [00:48<00:00,  1.05it/s]\n",
            "Epoch:  20% 1/5 [00:48<03:14, 48.65s/it]\n",
            "Iteration:   0% 0/51 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/51 [00:00<00:47,  1.05it/s]\u001b[A\n",
            "Iteration:   4% 2/51 [00:01<00:47,  1.04it/s]\u001b[A\n",
            "Iteration:   6% 3/51 [00:02<00:46,  1.03it/s]\u001b[A\n",
            "Iteration:   8% 4/51 [00:03<00:45,  1.03it/s]\u001b[A\n",
            "Iteration:  10% 5/51 [00:04<00:44,  1.03it/s]\u001b[A\n",
            "Iteration:  12% 6/51 [00:05<00:43,  1.03it/s]\u001b[A\n",
            "Iteration:  14% 7/51 [00:06<00:42,  1.03it/s]\u001b[A\n",
            "Iteration:  16% 8/51 [00:07<00:41,  1.03it/s]\u001b[A\n",
            "Iteration:  18% 9/51 [00:08<00:40,  1.03it/s]\u001b[A\n",
            "Iteration:  20% 10/51 [00:09<00:39,  1.03it/s]\u001b[A\n",
            "Iteration:  22% 11/51 [00:10<00:38,  1.03it/s]\u001b[A\n",
            "Iteration:  24% 12/51 [00:11<00:37,  1.03it/s]\u001b[A\n",
            "Iteration:  25% 13/51 [00:12<00:36,  1.03it/s]\u001b[A\n",
            "Iteration:  27% 14/51 [00:13<00:35,  1.03it/s]\u001b[A\n",
            "Iteration:  29% 15/51 [00:14<00:34,  1.04it/s]\u001b[A\n",
            "Iteration:  31% 16/51 [00:15<00:33,  1.03it/s]\u001b[A\n",
            "Iteration:  33% 17/51 [00:16<00:32,  1.04it/s]\u001b[A\n",
            "Iteration:  35% 18/51 [00:17<00:32,  1.03it/s]\u001b[A\n",
            "Iteration:  37% 19/51 [00:18<00:31,  1.03it/s]\u001b[A\n",
            "Iteration:  39% 20/51 [00:19<00:29,  1.04it/s]\u001b[A\n",
            "Iteration:  41% 21/51 [00:20<00:29,  1.03it/s]\u001b[A\n",
            "Iteration:  43% 22/51 [00:21<00:28,  1.03it/s]\u001b[A\n",
            "Iteration:  45% 23/51 [00:22<00:26,  1.04it/s]\u001b[A\n",
            "Iteration:  47% 24/51 [00:23<00:26,  1.04it/s]\u001b[A\n",
            "Iteration:  49% 25/51 [00:24<00:24,  1.04it/s]\u001b[A\n",
            "Iteration:  51% 26/51 [00:25<00:24,  1.03it/s]\u001b[A\n",
            "Iteration:  53% 27/51 [00:26<00:23,  1.03it/s]\u001b[A\n",
            "Iteration:  55% 28/51 [00:27<00:22,  1.04it/s]\u001b[A\n",
            "Iteration:  57% 29/51 [00:28<00:21,  1.03it/s]\u001b[A\n",
            "Iteration:  59% 30/51 [00:29<00:20,  1.03it/s]\u001b[A\n",
            "Iteration:  61% 31/51 [00:30<00:19,  1.03it/s]\u001b[A\n",
            "Iteration:  63% 32/51 [00:30<00:18,  1.03it/s]\u001b[A\n",
            "Iteration:  65% 33/51 [00:31<00:17,  1.03it/s]\u001b[A\n",
            "Iteration:  67% 34/51 [00:32<00:16,  1.03it/s]\u001b[A\n",
            "Iteration:  69% 35/51 [00:33<00:15,  1.03it/s]\u001b[A\n",
            "Iteration:  71% 36/51 [00:34<00:14,  1.03it/s]\u001b[A\n",
            "Iteration:  73% 37/51 [00:35<00:13,  1.04it/s]\u001b[A\n",
            "Iteration:  75% 38/51 [00:36<00:12,  1.04it/s]\u001b[A\n",
            "Iteration:  76% 39/51 [00:37<00:11,  1.03it/s]\u001b[A\n",
            "Iteration:  78% 40/51 [00:38<00:10,  1.03it/s]\u001b[A\n",
            "Iteration:  80% 41/51 [00:39<00:09,  1.03it/s]\u001b[A\n",
            "Iteration:  82% 42/51 [00:40<00:08,  1.03it/s]\u001b[A\n",
            "Iteration:  84% 43/51 [00:41<00:07,  1.03it/s]\u001b[A\n",
            "Iteration:  86% 44/51 [00:42<00:06,  1.03it/s]\u001b[A\n",
            "Iteration:  88% 45/51 [00:43<00:05,  1.04it/s]\u001b[A\n",
            "Iteration:  90% 46/51 [00:44<00:04,  1.04it/s]\u001b[A\n",
            "Iteration:  92% 47/51 [00:45<00:03,  1.04it/s]\u001b[A\n",
            "Iteration:  94% 48/51 [00:46<00:02,  1.04it/s]\u001b[A05/09/2022 10:58:25 - INFO - __main__ -   Creating features from dataset file at dataset\n",
            "finish loading examples\n",
            "number of processes for converting feature: 2\n",
            "1 processor started !\n",
            "2 processor started !\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   Writing example 0/87\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   Writing example 0/87\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 139 406 2807 2981 2508 2395 3813 3260 1491 2950 2629 3717 3530 1463 3461 1679 2924 2432 2660 325 3111 4035 3135 268 3077 707 2195 1419 32 652 5 707 3627 3519 4021 467 3879 411 1413 3123 2011 3867 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   guid: dev-88\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 1292 2523 3749 3260 1491 2950 2629 3589 3530 1462 3461 1679 2988 2511 2788 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2960 2557 2303 3\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   guid: dev-89\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   guid: dev-90\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 645 3267 138 342 2743 2981 2508 2523 3749 3258 1479 2950 2755 3781 3466 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1355 31 3724 5 707 3820 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   guid: dev-91\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 139 406 2807 2981 2508 2395 3813 3260 1491 2950 2629 3717 3530 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 3724 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3189 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2522 3266 1456 2960 2557 2303 3\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   guid: dev-92\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 645 3267 138 342 2743 2981 2508 2523 3813 3260 1491 2951 2755 3781 3467 1463 3528 1679 2988 2432 2660 325 3111 4035 3135 268 3077 707 2195 1419 32 652 5 707 3627 3519 4021 467 3879 411 1413 3123 2011 3867 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 181 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 1498 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:25 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:58:26 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:26 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "05/09/2022 10:58:26 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3760 1371 2987 940 2464 2383 2560 3650 1407 2176 3637 70 3718 3517 1526 698 697 67 3251 2115 901 434 647 442 746 2085 55 3091 701 694 499 3115 1285 3128 2719 438 1475 4035 195 735 2075 2512 2547 3980 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1727 1663 3915 4032 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3731 3355 3845 3331 155 3267 1499 1623 3\n",
            "05/09/2022 10:58:26 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:26 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:26 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   input_ids: 2 455 3757 1307 2987 940 2464 2383 2560 3650 1407 2240 3637 70 3720 3513 2550 698 697 67 3251 2115 901 434 647 442 748 2085 55 3091 701 694 499 3115 1285 3128 2655 438 1475 4035 195 735 2075 2512 2547 3980 3944 158 3511 392 3575 191 1119 3219 2059 2391 2213 3985 1354 3510 2750 1530 59 3423 3365 67 3842 1663 1663 3915 4029 647 4032 331 3717 699 3199 2103 2539 67 1526 7 2051 3571 2439 963 1407 903 3139 3347 1219 3603 3355 3845 3331 155 3266 1499 1623 3\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   guid: dev-5\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 645 3267 139 406 2615 2981 2508 2395 3813 3260 1491 2950 2629 3717 3338 1463 3461 1679 2924 2432 2660 325 3111 4035 3118 3532 3077 707 2195 1355 31 1676 5 707 3824 3455 4021 467 3879 411 1413 3123 2011 3995 3255 3948 1215 4029 2987 1525 428 1663 1718 112 1717 3545 135 2544 2067 351 751 3115 139 3756 2741 3987 195 2152 3403 3253 2495 3717 3765 1397 3136 5 394 3253 4035 1532 2999 3211 331 3980 3461 3123 448 2103 3235 7 3931 2523 3266 1456 2957 1533 2111 3\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 10:58:27 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 10:58:49 - INFO - __main__ -   Saving features into cached file dataset/cached_dev_DNABERT6_100_dnaprom\n",
            "05/09/2022 10:58:49 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "05/09/2022 10:58:49 - INFO - __main__ -     Num examples = 174\n",
            "05/09/2022 10:58:49 - INFO - __main__ -     Batch size = 32\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  17% 1/6 [00:00<00:01,  2.54it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33% 2/6 [00:00<00:01,  2.71it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 3/6 [00:01<00:01,  2.75it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67% 4/6 [00:01<00:00,  2.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  83% 5/6 [00:01<00:00,  2.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 6/6 [00:01<00:00,  3.03it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/09/2022 10:58:51 - INFO - __main__ -   ***** Eval results  *****\n",
            "05/09/2022 10:58:51 - INFO - __main__ -     acc = 0.42528735632183906\n",
            "05/09/2022 10:58:51 - INFO - __main__ -     auc = 0.5029729729729729\n",
            "05/09/2022 10:58:51 - INFO - __main__ -     f1 = 0.2983870967741935\n",
            "05/09/2022 10:58:51 - INFO - __main__ -     mcc = 0.0\n",
            "05/09/2022 10:58:51 - INFO - __main__ -     precision = 0.21264367816091953\n",
            "05/09/2022 10:58:51 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.42528735632183906, \"eval_f1\": 0.2983870967741935, \"eval_mcc\": 0.0, \"eval_auc\": 0.5029729729729729, \"eval_precision\": 0.21264367816091953, \"eval_recall\": 0.5, \"learning_rate\": 0.0001347826086956522, \"loss\": 0.7196783751249314, \"step\": 100}\n",
            "\n",
            "Iteration:  96% 49/51 [01:13<00:17,  8.87s/it]\u001b[A\n",
            "Iteration:  98% 50/51 [01:14<00:06,  6.50s/it]\u001b[A\n",
            "Iteration: 100% 51/51 [01:15<00:00,  1.47s/it]\n",
            "Epoch:  40% 2/5 [02:03<03:12, 64.16s/it]\n",
            "Iteration:   0% 0/51 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/51 [00:00<00:47,  1.05it/s]\u001b[A\n",
            "Iteration:   4% 2/51 [00:01<00:46,  1.04it/s]\u001b[A\n",
            "Iteration:   6% 3/51 [00:02<00:46,  1.04it/s]\u001b[A\n",
            "Iteration:   8% 4/51 [00:03<00:45,  1.03it/s]\u001b[A\n",
            "Iteration:  10% 5/51 [00:04<00:44,  1.03it/s]\u001b[A\n",
            "Iteration:  12% 6/51 [00:05<00:43,  1.03it/s]\u001b[A\n",
            "Iteration:  14% 7/51 [00:06<00:42,  1.03it/s]\u001b[A\n",
            "Iteration:  16% 8/51 [00:07<00:41,  1.04it/s]\u001b[A\n",
            "Iteration:  18% 9/51 [00:08<00:40,  1.04it/s]\u001b[A\n",
            "Iteration:  20% 10/51 [00:09<00:39,  1.04it/s]\u001b[A\n",
            "Iteration:  22% 11/51 [00:10<00:38,  1.04it/s]\u001b[A\n",
            "Iteration:  24% 12/51 [00:11<00:37,  1.04it/s]\u001b[A\n",
            "Iteration:  25% 13/51 [00:12<00:36,  1.04it/s]\u001b[A\n",
            "Iteration:  27% 14/51 [00:13<00:35,  1.04it/s]\u001b[A\n",
            "Iteration:  29% 15/51 [00:14<00:34,  1.03it/s]\u001b[A\n",
            "Iteration:  31% 16/51 [00:15<00:33,  1.04it/s]\u001b[A\n",
            "Iteration:  33% 17/51 [00:16<00:32,  1.04it/s]\u001b[A\n",
            "Iteration:  35% 18/51 [00:17<00:31,  1.04it/s]\u001b[A\n",
            "Iteration:  37% 19/51 [00:18<00:30,  1.05it/s]\u001b[A\n",
            "Iteration:  39% 20/51 [00:19<00:29,  1.05it/s]\u001b[A\n",
            "Iteration:  41% 21/51 [00:20<00:28,  1.05it/s]\u001b[A\n",
            "Iteration:  43% 22/51 [00:21<00:27,  1.04it/s]\u001b[A\n",
            "Iteration:  45% 23/51 [00:22<00:26,  1.04it/s]\u001b[A\n",
            "Iteration:  47% 24/51 [00:23<00:26,  1.04it/s]\u001b[A\n",
            "Iteration:  49% 25/51 [00:24<00:25,  1.03it/s]\u001b[A\n",
            "Iteration:  51% 26/51 [00:25<00:24,  1.03it/s]\u001b[A\n",
            "Iteration:  53% 27/51 [00:26<00:23,  1.03it/s]\u001b[A\n",
            "Iteration:  55% 28/51 [00:26<00:22,  1.03it/s]\u001b[A\n",
            "Iteration:  57% 29/51 [00:27<00:21,  1.03it/s]\u001b[A\n",
            "Iteration:  59% 30/51 [00:28<00:20,  1.03it/s]\u001b[A\n",
            "Iteration:  61% 31/51 [00:29<00:19,  1.03it/s]\u001b[A\n",
            "Iteration:  63% 32/51 [00:30<00:18,  1.03it/s]\u001b[A\n",
            "Iteration:  65% 33/51 [00:31<00:17,  1.03it/s]\u001b[A\n",
            "Iteration:  67% 34/51 [00:32<00:16,  1.03it/s]\u001b[A\n",
            "Iteration:  69% 35/51 [00:33<00:15,  1.03it/s]\u001b[A\n",
            "Iteration:  71% 36/51 [00:34<00:14,  1.03it/s]\u001b[A\n",
            "Iteration:  73% 37/51 [00:35<00:13,  1.03it/s]\u001b[A\n",
            "Iteration:  75% 38/51 [00:36<00:12,  1.03it/s]\u001b[A\n",
            "Iteration:  76% 39/51 [00:37<00:11,  1.03it/s]\u001b[A\n",
            "Iteration:  78% 40/51 [00:38<00:10,  1.03it/s]\u001b[A\n",
            "Iteration:  80% 41/51 [00:39<00:09,  1.03it/s]\u001b[A\n",
            "Iteration:  82% 42/51 [00:40<00:08,  1.03it/s]\u001b[A\n",
            "Iteration:  84% 43/51 [00:41<00:07,  1.02it/s]\u001b[A\n",
            "Iteration:  86% 44/51 [00:42<00:06,  1.03it/s]\u001b[A\n",
            "Iteration:  88% 45/51 [00:43<00:05,  1.03it/s]\u001b[A\n",
            "Iteration:  90% 46/51 [00:44<00:04,  1.03it/s]\u001b[A\n",
            "Iteration:  92% 47/51 [00:45<00:03,  1.03it/s]\u001b[A\n",
            "Iteration:  94% 48/51 [00:46<00:02,  1.03it/s]\u001b[A\n",
            "Iteration:  96% 49/51 [00:47<00:01,  1.03it/s]\u001b[A\n",
            "Iteration:  98% 50/51 [00:48<00:00,  1.03it/s]\u001b[A\n",
            "Iteration: 100% 51/51 [00:48<00:00,  1.05it/s]\n",
            "Epoch:  60% 3/5 [02:52<01:54, 57.09s/it]\n",
            "Iteration:   0% 0/51 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/51 [00:00<00:47,  1.05it/s]\u001b[A\n",
            "Iteration:   4% 2/51 [00:01<00:47,  1.04it/s]\u001b[A\n",
            "Iteration:   6% 3/51 [00:02<00:46,  1.03it/s]\u001b[A\n",
            "Iteration:   8% 4/51 [00:03<00:45,  1.03it/s]\u001b[A\n",
            "Iteration:  10% 5/51 [00:04<00:44,  1.03it/s]\u001b[A\n",
            "Iteration:  12% 6/51 [00:05<00:43,  1.03it/s]\u001b[A\n",
            "Iteration:  14% 7/51 [00:06<00:42,  1.03it/s]\u001b[A\n",
            "Iteration:  16% 8/51 [00:07<00:41,  1.03it/s]\u001b[A\n",
            "Iteration:  18% 9/51 [00:08<00:40,  1.03it/s]\u001b[A\n",
            "Iteration:  20% 10/51 [00:09<00:39,  1.03it/s]\u001b[A\n",
            "Iteration:  22% 11/51 [00:10<00:38,  1.03it/s]\u001b[A\n",
            "Iteration:  24% 12/51 [00:11<00:37,  1.03it/s]\u001b[A\n",
            "Iteration:  25% 13/51 [00:12<00:36,  1.03it/s]\u001b[A\n",
            "Iteration:  27% 14/51 [00:13<00:35,  1.03it/s]\u001b[A\n",
            "Iteration:  29% 15/51 [00:14<00:34,  1.03it/s]\u001b[A\n",
            "Iteration:  31% 16/51 [00:15<00:33,  1.03it/s]\u001b[A\n",
            "Iteration:  33% 17/51 [00:16<00:32,  1.03it/s]\u001b[A\n",
            "Iteration:  35% 18/51 [00:17<00:32,  1.03it/s]\u001b[A\n",
            "Iteration:  37% 19/51 [00:18<00:31,  1.02it/s]\u001b[A\n",
            "Iteration:  39% 20/51 [00:19<00:30,  1.03it/s]\u001b[A\n",
            "Iteration:  41% 21/51 [00:20<00:29,  1.03it/s]\u001b[A\n",
            "Iteration:  43% 22/51 [00:21<00:28,  1.03it/s]\u001b[A\n",
            "Iteration:  45% 23/51 [00:22<00:27,  1.03it/s]\u001b[A\n",
            "Iteration:  47% 24/51 [00:23<00:26,  1.03it/s]\u001b[A\n",
            "Iteration:  49% 25/51 [00:24<00:25,  1.03it/s]\u001b[A\n",
            "Iteration:  51% 26/51 [00:25<00:24,  1.03it/s]\u001b[A\n",
            "Iteration:  53% 27/51 [00:26<00:23,  1.03it/s]\u001b[A\n",
            "Iteration:  55% 28/51 [00:27<00:22,  1.03it/s]\u001b[A\n",
            "Iteration:  57% 29/51 [00:28<00:21,  1.03it/s]\u001b[A\n",
            "Iteration:  59% 30/51 [00:29<00:20,  1.03it/s]\u001b[A\n",
            "Iteration:  61% 31/51 [00:30<00:19,  1.03it/s]\u001b[A\n",
            "Iteration:  63% 32/51 [00:31<00:18,  1.03it/s]\u001b[A\n",
            "Iteration:  65% 33/51 [00:32<00:17,  1.03it/s]\u001b[A\n",
            "Iteration:  67% 34/51 [00:32<00:16,  1.03it/s]\u001b[A\n",
            "Iteration:  69% 35/51 [00:33<00:15,  1.03it/s]\u001b[A\n",
            "Iteration:  71% 36/51 [00:34<00:14,  1.03it/s]\u001b[A\n",
            "Iteration:  73% 37/51 [00:35<00:13,  1.03it/s]\u001b[A\n",
            "Iteration:  75% 38/51 [00:36<00:12,  1.03it/s]\u001b[A\n",
            "Iteration:  76% 39/51 [00:37<00:11,  1.03it/s]\u001b[A\n",
            "Iteration:  78% 40/51 [00:38<00:10,  1.03it/s]\u001b[A\n",
            "Iteration:  80% 41/51 [00:39<00:09,  1.03it/s]\u001b[A\n",
            "Iteration:  82% 42/51 [00:40<00:08,  1.04it/s]\u001b[A\n",
            "Iteration:  84% 43/51 [00:41<00:07,  1.03it/s]\u001b[A\n",
            "Iteration:  86% 44/51 [00:42<00:06,  1.04it/s]\u001b[A\n",
            "Iteration:  88% 45/51 [00:43<00:05,  1.04it/s]\u001b[A\n",
            "Iteration:  90% 46/51 [00:44<00:04,  1.03it/s]\u001b[A05/09/2022 11:00:26 - INFO - __main__ -   Loading features from cached file dataset/cached_dev_DNABERT6_100_dnaprom\n",
            "05/09/2022 11:00:26 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "05/09/2022 11:00:26 - INFO - __main__ -     Num examples = 174\n",
            "05/09/2022 11:00:26 - INFO - __main__ -     Batch size = 32\n",
            "\n",
            "\n",
            "Evaluating:   0% 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  17% 1/6 [00:00<00:01,  3.06it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  33% 2/6 [00:00<00:01,  3.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  50% 3/6 [00:00<00:00,  3.02it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  67% 4/6 [00:01<00:00,  3.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating:  83% 5/6 [00:01<00:00,  3.00it/s]\u001b[A\u001b[A\n",
            "\n",
            "Evaluating: 100% 6/6 [00:01<00:00,  3.27it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/09/2022 11:00:28 - INFO - __main__ -   ***** Eval results  *****\n",
            "05/09/2022 11:00:28 - INFO - __main__ -     acc = 0.5747126436781609\n",
            "05/09/2022 11:00:28 - INFO - __main__ -     auc = 0.5039864864864865\n",
            "05/09/2022 11:00:28 - INFO - __main__ -     f1 = 0.36496350364963503\n",
            "05/09/2022 11:00:28 - INFO - __main__ -     mcc = 0.0\n",
            "05/09/2022 11:00:28 - INFO - __main__ -     precision = 0.28735632183908044\n",
            "05/09/2022 11:00:28 - INFO - __main__ -     recall = 0.5\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"eval_acc\": 0.5747126436781609, \"eval_f1\": 0.36496350364963503, \"eval_mcc\": 0.0, \"eval_auc\": 0.5039864864864865, \"eval_precision\": 0.28735632183908044, \"eval_recall\": 0.5, \"learning_rate\": 4.782608695652174e-05, \"loss\": 0.7072443270683288, \"step\": 200}\n",
            "\n",
            "Iteration:  92% 47/51 [00:47<00:06,  1.53s/it]\u001b[A\n",
            "Iteration:  94% 48/51 [00:48<00:04,  1.35s/it]\u001b[A\n",
            "Iteration:  96% 49/51 [00:49<00:02,  1.24s/it]\u001b[A\n",
            "Iteration:  98% 50/51 [00:50<00:01,  1.16s/it]\u001b[A\n",
            "Iteration: 100% 51/51 [00:50<00:00,  1.01it/s]\n",
            "Epoch:  80% 4/5 [03:42<00:54, 54.53s/it]\n",
            "Iteration:   0% 0/51 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/51 [00:00<00:47,  1.04it/s]\u001b[A\n",
            "Iteration:   4% 2/51 [00:01<00:47,  1.04it/s]\u001b[A\n",
            "Iteration:   6% 3/51 [00:02<00:46,  1.04it/s]\u001b[A\n",
            "Iteration:   8% 4/51 [00:03<00:45,  1.03it/s]\u001b[A\n",
            "Iteration:  10% 5/51 [00:04<00:44,  1.03it/s]\u001b[A\n",
            "Iteration:  12% 6/51 [00:05<00:43,  1.04it/s]\u001b[A\n",
            "Iteration:  14% 7/51 [00:06<00:42,  1.03it/s]\u001b[A\n",
            "Iteration:  16% 8/51 [00:07<00:41,  1.03it/s]\u001b[A\n",
            "Iteration:  18% 9/51 [00:08<00:40,  1.03it/s]\u001b[A\n",
            "Iteration:  20% 10/51 [00:09<00:39,  1.03it/s]\u001b[A\n",
            "Iteration:  22% 11/51 [00:10<00:38,  1.03it/s]\u001b[A\n",
            "Iteration:  24% 12/51 [00:11<00:37,  1.03it/s]\u001b[A\n",
            "Iteration:  25% 13/51 [00:12<00:37,  1.03it/s]\u001b[A\n",
            "Iteration:  27% 14/51 [00:13<00:36,  1.03it/s]\u001b[A\n",
            "Iteration:  29% 15/51 [00:14<00:35,  1.03it/s]\u001b[A\n",
            "Iteration:  31% 16/51 [00:15<00:34,  1.03it/s]\u001b[A\n",
            "Iteration:  33% 17/51 [00:16<00:33,  1.03it/s]\u001b[A\n",
            "Iteration:  35% 18/51 [00:17<00:31,  1.03it/s]\u001b[A\n",
            "Iteration:  37% 19/51 [00:18<00:30,  1.03it/s]\u001b[A\n",
            "Iteration:  39% 20/51 [00:19<00:30,  1.03it/s]\u001b[A\n",
            "Iteration:  41% 21/51 [00:20<00:29,  1.03it/s]\u001b[A\n",
            "Iteration:  43% 22/51 [00:21<00:28,  1.03it/s]\u001b[A\n",
            "Iteration:  45% 23/51 [00:22<00:27,  1.03it/s]\u001b[A\n",
            "Iteration:  47% 24/51 [00:23<00:26,  1.03it/s]\u001b[A\n",
            "Iteration:  49% 25/51 [00:24<00:25,  1.04it/s]\u001b[A\n",
            "Iteration:  51% 26/51 [00:25<00:24,  1.03it/s]\u001b[A\n",
            "Iteration:  53% 27/51 [00:26<00:23,  1.03it/s]\u001b[A\n",
            "Iteration:  55% 28/51 [00:27<00:22,  1.03it/s]\u001b[A\n",
            "Iteration:  57% 29/51 [00:28<00:21,  1.03it/s]\u001b[A\n",
            "Iteration:  59% 30/51 [00:29<00:20,  1.04it/s]\u001b[A\n",
            "Iteration:  61% 31/51 [00:30<00:19,  1.03it/s]\u001b[A\n",
            "Iteration:  63% 32/51 [00:30<00:18,  1.03it/s]\u001b[A\n",
            "Iteration:  65% 33/51 [00:31<00:17,  1.04it/s]\u001b[A\n",
            "Iteration:  67% 34/51 [00:32<00:16,  1.03it/s]\u001b[A\n",
            "Iteration:  69% 35/51 [00:33<00:15,  1.03it/s]\u001b[A\n",
            "Iteration:  71% 36/51 [00:34<00:14,  1.03it/s]\u001b[A\n",
            "Iteration:  73% 37/51 [00:35<00:13,  1.03it/s]\u001b[A\n",
            "Iteration:  75% 38/51 [00:36<00:12,  1.03it/s]\u001b[A\n",
            "Iteration:  76% 39/51 [00:37<00:11,  1.03it/s]\u001b[A\n",
            "Iteration:  78% 40/51 [00:38<00:10,  1.03it/s]\u001b[A\n",
            "Iteration:  80% 41/51 [00:39<00:09,  1.03it/s]\u001b[A\n",
            "Iteration:  82% 42/51 [00:40<00:08,  1.04it/s]\u001b[A\n",
            "Iteration:  84% 43/51 [00:41<00:07,  1.04it/s]\u001b[A\n",
            "Iteration:  86% 44/51 [00:42<00:06,  1.04it/s]\u001b[A\n",
            "Iteration:  88% 45/51 [00:43<00:05,  1.03it/s]\u001b[A\n",
            "Iteration:  90% 46/51 [00:44<00:04,  1.03it/s]\u001b[A\n",
            "Iteration:  92% 47/51 [00:45<00:03,  1.03it/s]\u001b[A\n",
            "Iteration:  94% 48/51 [00:46<00:02,  1.03it/s]\u001b[A\n",
            "Iteration:  96% 49/51 [00:47<00:01,  1.03it/s]\u001b[A\n",
            "Iteration:  98% 50/51 [00:48<00:00,  1.03it/s]\u001b[A\n",
            "Iteration: 100% 51/51 [00:48<00:00,  1.05it/s]\n",
            "Epoch: 100% 5/5 [04:31<00:00, 54.33s/it]\n",
            "05/09/2022 11:01:20 - INFO - __main__ -    global_step = 255, average loss = 0.710735063459359\n",
            "05/09/2022 11:01:20 - INFO - __main__ -   Saving model checkpoint to output\n",
            "05/09/2022 11:01:20 - INFO - transformers.configuration_utils -   Configuration saved in output/config.json\n",
            "05/09/2022 11:01:21 - INFO - transformers.modeling_utils -   Model weights saved in output/pytorch_model.bin\n",
            "05/09/2022 11:01:21 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n",
            "05/09/2022 11:01:21 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "05/09/2022 11:01:21 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file output/vocab.txt\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file output/vocab.txt\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n",
            "05/09/2022 11:01:24 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n",
            "05/09/2022 11:01:24 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n",
            "05/09/2022 11:01:24 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n",
            "05/09/2022 11:01:24 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "05/09/2022 11:01:24 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n",
            "05/09/2022 11:01:26 - INFO - __main__ -   Loading features from cached file dataset/cached_dev_DNABERT6_100_dnaprom\n",
            "05/09/2022 11:01:26 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "05/09/2022 11:01:26 - INFO - __main__ -     Num examples = 174\n",
            "05/09/2022 11:01:26 - INFO - __main__ -     Batch size = 32\n",
            "Evaluating: 100% 6/6 [00:02<00:00,  3.00it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/09/2022 11:01:28 - INFO - __main__ -   ***** Eval results  *****\n",
            "05/09/2022 11:01:28 - INFO - __main__ -     acc = 0.5747126436781609\n",
            "05/09/2022 11:01:28 - INFO - __main__ -     auc = 0.5268918918918919\n",
            "05/09/2022 11:01:28 - INFO - __main__ -     f1 = 0.36496350364963503\n",
            "05/09/2022 11:01:28 - INFO - __main__ -     mcc = 0.0\n",
            "05/09/2022 11:01:28 - INFO - __main__ -     precision = 0.28735632183908044\n",
            "05/09/2022 11:01:28 - INFO - __main__ -     recall = 0.5\n"
          ]
        }
      ],
      "source": [
        "!python DNABERT/examples/run_finetune.py \\\n",
        "    --model_type dna \\\n",
        "    --tokenizer_name=dna$KMER \\\n",
        "    --model_name_or_path $MODEL_PATH \\\n",
        "    --task_name dnaprom \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --data_dir $DATA_PATH \\\n",
        "    --max_seq_length 100 \\\n",
        "    --per_gpu_eval_batch_size=32   \\\n",
        "    --per_gpu_train_batch_size=32   \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --num_train_epochs $EPOCHS \\\n",
        "    --output_dir $OUTPUT_PATH \\\n",
        "    --evaluate_during_training \\\n",
        "    --logging_steps 100 \\\n",
        "    --save_steps 4000 \\\n",
        "    --warmup_percent 0.1 \\\n",
        "    --hidden_dropout_prob 0.1 \\\n",
        "    --overwrite_output \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --n_process 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDUMd4JM1OP8"
      },
      "outputs": [],
      "source": [
        "# 05/03/2022 11:28:33 - INFO - __main__ -   ***** Eval results  *****\n",
        "# 05/03/2022 11:28:33 - INFO - __main__ -     acc = 0.9833333333333333\n",
        "# 05/03/2022 11:28:33 - INFO - __main__ -     auc = 0.9916666666666666\n",
        "# 05/03/2022 11:28:33 - INFO - __main__ -     f1 = 0.983328702417338\n",
        "# 05/03/2022 11:28:33 - INFO - __main__ -     mcc = 0.9672041516493516\n",
        "# 05/03/2022 11:28:33 - INFO - __main__ -     precision = 0.9838709677419355\n",
        "# 05/03/2022 11:28:33 - INFO - __main__ -     recall = 0.9833333333333334"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_u5WhZBVymt"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dP_oD4jV2Bi"
      },
      "outputs": [],
      "source": [
        "KMER = K\n",
        "MODEL_PATH='output'\n",
        "DATA_PATH='test'\n",
        "PREDICTION_PATH='prediction'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIT9SRbKV0PS",
        "outputId": "5a967b3d-003d-47aa-eb28-9a784e08d4be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "05/09/2022 11:01:43 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "05/09/2022 11:01:43 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n",
            "05/09/2022 11:01:43 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "05/09/2022 11:01:43 - INFO - transformers.tokenization_utils -   loading file https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/vocab.txt from cache at /root/.cache/torch/transformers/ea1474aad40c1c8ed4e1cb7c11345ddda6df27a857fb29e1d4c901d9b900d32d.26f8bd5a32e49c2a8271a46950754a4a767726709b7741c68723bc1db840a87e\n",
            "05/09/2022 11:01:43 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n",
            "05/09/2022 11:01:46 - INFO - __main__ -   finish loading model\n",
            "05/09/2022 11:01:49 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, attention_probs_dropout_prob=0.1, beta1=0.9, beta2=0.999, cache_dir='', config_name='', data_dir='test', device=device(type='cuda'), do_ensemble_pred=False, do_eval=False, do_lower_case=False, do_predict=True, do_train=False, do_visualize=False, early_stop=0, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, hidden_dropout_prob=0.1, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=75, max_steps=-1, model_name_or_path='output', model_type='dna', n_gpu=1, n_process=48, no_cuda=False, num_rnn_layer=2, num_train_epochs=3.0, output_dir='output', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_pred_batch_size=128, per_gpu_train_batch_size=8, predict_dir='prediction', predict_scan_size=1, result_dir=None, rnn='lstm', rnn_dropout=0.0, rnn_hidden=768, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, task_name='dnaprom', tokenizer_name='dna6', visualize_data_dir=None, visualize_models=None, visualize_train=False, warmup_percent=0, warmup_steps=0, weight_decay=0.0)\n",
            "============================================================\n",
            "<class 'transformers.tokenization_dna.DNATokenizer'>\n",
            "05/09/2022 11:01:49 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (dna3, dna4, dna5, dna6). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/09/2022 11:01:49 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n",
            "05/09/2022 11:01:49 - INFO - transformers.tokenization_utils -   loading file output/vocab.txt\n",
            "05/09/2022 11:01:49 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/09/2022 11:01:49 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n",
            "05/09/2022 11:01:49 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n",
            "05/09/2022 11:01:49 - INFO - __main__ -   Predict using the following checkpoint: output\n",
            "05/09/2022 11:01:49 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n",
            "05/09/2022 11:01:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": \"dnaprom\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"num_rnn_layer\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "05/09/2022 11:01:49 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n",
            "05/09/2022 11:01:51 - INFO - __main__ -   Creating features from dataset file at test\n",
            "finish loading examples\n",
            "number of processes for converting feature: 12\n",
            "1 processor started !\n",
            "2 processor started !\n",
            "3 processor started !\n",
            "4 processor started !\n",
            "5 processor started !\n",
            "6 processor started !\n",
            "7 processor started !\n",
            "8 processor started !\n",
            "9 processor started !\n",
            "10 processor started !\n",
            "11 processor started !\n",
            "12 processor started !\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/16\n",
            "05/09/2022 11:01:52 - INFO - transformers.data.processors.glue -   Writing example 0/24\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-33\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-65\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-81\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-17\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-97\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-145\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2951 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-129\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-113\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-161\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   guid: dev-177\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2951 3\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:53 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-34\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-66\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-82\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1826 3194 476 1890 3450 1499 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3545 1877 3400 1299 1087 240 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-98\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-18\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-146\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2951 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-162\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1826 3194 476 1890 3450 1499 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3545 1877 3400 1299 1087 240 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-130\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-114\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2951 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   guid: dev-178\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:54 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-35\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-67\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-83\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-99\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-147\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-19\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-163\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-131\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 2554 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3545 1877 3400 1299 1087 240 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   guid: dev-115\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   guid: dev-179\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   guid: dev-68\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   guid: dev-36\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   input_ids: 2 2554 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3545 1877 3400 1299 1087 240 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   guid: dev-84\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   guid: dev-100\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   guid: dev-148\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:56 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-20\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2951 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-164\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1826 3194 476 1890 3450 1499 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3545 1877 3400 1299 1087 240 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-116\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-132\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-180\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-69\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-37\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-85\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   guid: dev-101\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   input_ids: 2 2554 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3545 1877 3400 1299 1087 240 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:57 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   guid: dev-149\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   guid: dev-21\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   guid: dev-117\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1136 436 1729 2807 3023 3888 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   guid: dev-181\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   guid: dev-133\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3718 2570 2073 85 326 1292 1059 126 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   guid: dev-49\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   input_ids: 2 455 1808 3123 191 751 2991 3760 2738 2746 2778 2906 3418 1371 1375 1392 1459 1727 2798 2987 3741 2664 2451 1599 2286 940 3747 2686 2539 1950 3691 2464 1651 2494 1771 2973 3687 2445 1575 2190 554 2204 611 2432 1524 1987 3837 3048 3988 3651 2302 1002 3994 3676 2403 1407 1519 1965 3751 2704 2611 2240 756 3011 3837 3048 3988 3651 2301 997 3975 3600 2099 191 3\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:58 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:01:59 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:01:59 - INFO - transformers.data.processors.glue -   guid: dev-50\n",
            "05/09/2022 11:01:59 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:01:59 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:01:59 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:01:59 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   input_ids: 2 455 1808 3123 191 751 2991 3760 2738 2746 2778 2906 3418 1371 1375 1392 1459 1727 2798 2987 3741 2664 2451 1599 2286 940 3747 2686 2539 1950 3691 2464 1651 2494 1770 2969 3671 2383 1327 1198 684 2724 2691 2560 2036 4035 3837 3048 3988 3650 2298 986 3930 3420 1379 1407 1519 1965 3750 2700 2595 2176 500 1987 3837 3048 3985 3637 2245 773 3078 9 21 70 3\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   guid: dev-51\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   input_ids: 2 3386 1241 855 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 139 541 2150 395 1566 2153 406 1611 2335 1133 424 1681 2615 2255 816 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 490 1946 3674 2395 1376 1395 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2950 3\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:02:00 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1472 1779 3005 3813 2952 3601 2103 208 818 3260 738 2938 3548 1889 3448 1491 1855 3312 947 3773 2789 2951 3\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   guid: dev-52\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:02:01 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   guid: dev-5\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   input_ids: 2 3578 2009 3927 3407 1325 1189 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   guid: dev-53\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   input_ids: 2 3579 2013 3943 3471 1581 2213 645 2568 2065 55 208 820 3267 765 3045 3975 3597 2086 138 537 2134 330 1306 1113 342 1355 1311 1135 432 1713 2743 2767 2864 3251 703 2797 2981 3719 2574 2092 161 630 2508 1827 3198 492 1954 3706 2523 1888 3443 1471 1775 2989 3749 2696 2577 2103 208 818 3258 730 2906 3420 1377 1397 1479 1807 3120 179 701 2789 2950 3\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:02:02 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "05/09/2022 11:02:03 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "05/09/2022 11:02:03 - INFO - transformers.data.processors.glue -   guid: dev-165\n",
            "05/09/2022 11:02:03 - INFO - transformers.data.processors.glue -   input_ids: 2 455 1808 3123 191 751 2991 3760 2738 2746 2778 2906 3418 1371 1375 1392 1459 1727 2798 2987 3741 2664 2451 1599 2286 940 3747 2686 2539 1950 3691 2464 1651 2494 1770 2969 3671 2383 1327 1198 684 2724 2691 2560 2036 4035 3837 3048 3988 3650 2298 986 3930 3420 1379 1407 1519 1965 3750 2700 2595 2176 500 1987 3837 3048 3985 3637 2245 773 3078 9 21 70 3\n",
            "05/09/2022 11:02:03 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "05/09/2022 11:02:03 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "05/09/2022 11:02:03 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "05/09/2022 11:02:15 - INFO - __main__ -   Saving features into cached file test/cached_dev_75_dnaprom\n",
            "05/09/2022 11:02:15 - INFO - __main__ -   ***** Running prediction  *****\n",
            "05/09/2022 11:02:15 - INFO - __main__ -     Num examples = 200\n",
            "05/09/2022 11:02:15 - INFO - __main__ -     Batch size = 128\n",
            "Predicting: 100% 2/2 [00:01<00:00,  1.18it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "05/09/2022 11:02:16 - INFO - __main__ -   ***** Pred results  *****\n",
            "05/09/2022 11:02:16 - INFO - __main__ -     acc = 0.5\n",
            "05/09/2022 11:02:16 - INFO - __main__ -     auc = 0.5601\n",
            "05/09/2022 11:02:16 - INFO - __main__ -     f1 = 0.3333333333333333\n",
            "05/09/2022 11:02:16 - INFO - __main__ -     mcc = 0.0\n",
            "05/09/2022 11:02:16 - INFO - __main__ -     precision = 0.25\n",
            "05/09/2022 11:02:16 - INFO - __main__ -     recall = 0.5\n"
          ]
        }
      ],
      "source": [
        "!python DNABERT/examples/run_finetune.py \\\n",
        "    --model_type dna \\\n",
        "    --tokenizer_name=dna$KMER \\\n",
        "    --model_name_or_path $MODEL_PATH \\\n",
        "    --task_name dnaprom \\\n",
        "    --do_predict \\\n",
        "    --data_dir $DATA_PATH  \\\n",
        "    --max_seq_length 75 \\\n",
        "    --per_gpu_pred_batch_size=128   \\\n",
        "    --output_dir $MODEL_PATH \\\n",
        "    --predict_dir $PREDICTION_PATH \\\n",
        "    --n_process 48"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRe9SLHtm1hp"
      },
      "source": [
        "## Remove cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PiWI2sXmiSz",
        "outputId": "329456ea-30dd-4246-f900-38536fbea200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'test/cached*': No such file or directory\n",
            "rm: cannot remove 'dataset/cached*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r test/cached*\n",
        "!rm -r dataset/cached*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Mqj8YwVtpx"
      },
      "source": [
        "## Get IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYtCX1ndZ79v"
      },
      "outputs": [],
      "source": [
        "START = 300\n",
        "N_SAMPLES = 300\n",
        "\n",
        "CARRIER = BASE_PATH + \"ids_carrier.txt\"\n",
        "MENING_SEPT = BASE_PATH + \"ids_meningitis_septicaemia.txt\"\n",
        "\n",
        "def getIds(path=CARRIER, id_start=START, n_samples=N_SAMPLES):\n",
        "  my_file = open(path, \"r\")\n",
        "  content_list = my_file.readlines()\n",
        "  lista = [int(x) for x in content_list[id_start:id_start+n_samples]]\n",
        "  # for n in lista:\n",
        "  #   print(n)\n",
        "  return lista\n",
        "\n",
        "carrier_set = getIds(CARRIER, id_start=1000, n_samples=100)\n",
        "mening_set = getIds(MENING_SEPT, id_start=1000, n_samples=100)\n",
        "test_set = carrier_set + mening_set\n",
        "random.shuffle(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfapewaARfO_",
        "outputId": "e2b72529-6c42-4189-dad4-37b555a322d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2195\n",
            "92282\n",
            "92771\n",
            "92091\n",
            "92346\n",
            "2172\n",
            "92264\n",
            "92108\n",
            "2277\n",
            "2240\n",
            "92237\n",
            "92381\n",
            "2177\n",
            "92110\n",
            "92231\n",
            "92017\n",
            "92156\n",
            "2161\n",
            "2160\n",
            "92142\n",
            "92307\n",
            "2194\n",
            "92377\n",
            "92035\n",
            "2175\n",
            "2278\n",
            "92096\n",
            "2186\n",
            "92049\n",
            "92451\n",
            "2205\n",
            "2171\n",
            "92763\n",
            "92308\n",
            "2158\n",
            "92173\n",
            "92241\n",
            "92155\n",
            "92759\n",
            "2169\n",
            "2215\n",
            "2153\n",
            "2174\n",
            "92403\n",
            "92065\n",
            "2189\n",
            "92078\n",
            "2199\n",
            "92461\n",
            "92425\n",
            "2182\n",
            "92080\n",
            "92086\n",
            "2187\n",
            "2168\n",
            "2178\n",
            "92199\n",
            "2234\n",
            "92860\n",
            "2188\n",
            "2151\n",
            "92141\n",
            "92330\n",
            "92211\n",
            "92187\n",
            "2159\n",
            "92212\n",
            "2190\n",
            "92140\n",
            "2200\n",
            "2197\n",
            "92064\n",
            "2254\n",
            "92414\n",
            "2279\n",
            "92068\n",
            "2179\n",
            "92234\n",
            "2241\n",
            "2236\n",
            "2235\n",
            "2176\n",
            "2180\n",
            "2223\n",
            "92364\n",
            "92321\n",
            "2261\n",
            "92340\n",
            "2183\n",
            "92376\n",
            "92453\n",
            "2184\n",
            "2256\n",
            "2226\n",
            "2263\n",
            "92221\n",
            "92284\n",
            "92290\n",
            "92137\n",
            "2193\n",
            "2191\n",
            "92271\n",
            "2265\n",
            "92188\n",
            "2258\n",
            "92447\n",
            "92196\n",
            "92341\n",
            "2232\n",
            "2225\n",
            "2210\n",
            "2239\n",
            "92112\n",
            "2162\n",
            "2259\n",
            "2152\n",
            "2202\n",
            "2208\n",
            "2255\n",
            "92194\n",
            "2229\n",
            "92227\n",
            "2154\n",
            "92168\n",
            "2228\n",
            "92356\n",
            "92191\n",
            "92280\n",
            "92448\n",
            "2231\n",
            "2260\n",
            "2185\n",
            "2173\n",
            "2238\n",
            "92242\n",
            "2166\n",
            "92025\n",
            "92430\n",
            "2163\n",
            "2167\n",
            "2217\n",
            "2164\n",
            "92217\n",
            "92164\n",
            "2230\n",
            "2262\n",
            "2165\n",
            "92384\n",
            "92441\n",
            "92040\n",
            "2203\n",
            "92088\n",
            "92131\n",
            "92329\n",
            "2201\n",
            "92292\n",
            "92223\n",
            "2196\n",
            "92395\n",
            "2209\n",
            "92092\n",
            "92053\n",
            "2221\n",
            "2266\n",
            "2207\n",
            "2224\n",
            "92435\n",
            "92159\n",
            "2257\n",
            "2155\n",
            "92081\n",
            "2192\n",
            "92300\n",
            "2181\n",
            "2204\n",
            "92028\n",
            "2227\n",
            "2211\n",
            "92098\n",
            "2213\n",
            "92844\n",
            "92281\n",
            "92067\n",
            "2156\n",
            "92236\n",
            "92052\n",
            "92306\n",
            "92420\n",
            "92114\n",
            "92125\n",
            "92123\n",
            "2222\n",
            "2220\n",
            "92213\n",
            "2264\n",
            "2198\n",
            "92288\n",
            "2218\n",
            "2170\n",
            "2242\n"
          ]
        }
      ],
      "source": [
        "for el in test_set:\n",
        "  print(el)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "549AUOA7R4O7",
        "outputId": "99e4a1c6-6325-4d15-addf-1a3689c0d0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2141\n",
            "2142\n",
            "2144\n",
            "2145\n",
            "2146\n",
            "2147\n",
            "2148\n",
            "2149\n",
            "2150\n",
            "2151\n",
            "2152\n",
            "2153\n",
            "2154\n",
            "2155\n",
            "2156\n",
            "2158\n",
            "2159\n",
            "2160\n",
            "2161\n",
            "2162\n",
            "2163\n",
            "2164\n",
            "2165\n",
            "2166\n",
            "2167\n",
            "2168\n",
            "2169\n",
            "2170\n",
            "2171\n",
            "2172\n",
            "2173\n",
            "2174\n",
            "2175\n",
            "2176\n",
            "2177\n",
            "2178\n",
            "2179\n",
            "2180\n",
            "2181\n",
            "2182\n",
            "2183\n",
            "2184\n",
            "2185\n",
            "2186\n",
            "2187\n",
            "2188\n",
            "2189\n",
            "2190\n",
            "2191\n",
            "2192\n",
            "2193\n",
            "2194\n",
            "2195\n",
            "2196\n",
            "2197\n",
            "2198\n",
            "2199\n",
            "2200\n",
            "2201\n",
            "2202\n",
            "2203\n",
            "2204\n",
            "2205\n",
            "2207\n",
            "2208\n",
            "2209\n",
            "2210\n",
            "2211\n",
            "2213\n",
            "2215\n",
            "2217\n",
            "2218\n",
            "2220\n",
            "2221\n",
            "2222\n",
            "2223\n",
            "2224\n",
            "2225\n",
            "2226\n",
            "2227\n",
            "2228\n",
            "2229\n",
            "2230\n",
            "2231\n",
            "2232\n",
            "2234\n",
            "2235\n",
            "2236\n",
            "2238\n",
            "2239\n",
            "2240\n",
            "2241\n",
            "2242\n",
            "2254\n",
            "2255\n",
            "2256\n",
            "2257\n",
            "2258\n",
            "2259\n",
            "2260\n",
            "2261\n",
            "2262\n",
            "2263\n",
            "2264\n",
            "2265\n",
            "2266\n",
            "2277\n",
            "2278\n",
            "2279\n",
            "2280\n",
            "2329\n",
            "2330\n",
            "2331\n",
            "2332\n",
            "2333\n",
            "2334\n",
            "2335\n",
            "2336\n",
            "2337\n",
            "2338\n",
            "2339\n",
            "2340\n",
            "2341\n",
            "2342\n",
            "2343\n",
            "2344\n",
            "2345\n",
            "2346\n",
            "2347\n",
            "2348\n",
            "2358\n",
            "2359\n",
            "2360\n",
            "2361\n",
            "2365\n",
            "2366\n",
            "2367\n",
            "2368\n",
            "2369\n",
            "2370\n",
            "2371\n",
            "2372\n",
            "2373\n",
            "2374\n",
            "2375\n",
            "2376\n",
            "2377\n",
            "2378\n",
            "2379\n",
            "2380\n",
            "2381\n",
            "2382\n",
            "2383\n",
            "2384\n",
            "2385\n",
            "2386\n",
            "2387\n",
            "2388\n",
            "2389\n",
            "2390\n",
            "2391\n",
            "2392\n",
            "2393\n",
            "2394\n",
            "2395\n",
            "2396\n",
            "2397\n",
            "2398\n",
            "2399\n",
            "2400\n",
            "2401\n",
            "2402\n",
            "2403\n",
            "2404\n",
            "2405\n",
            "2406\n",
            "2407\n",
            "2408\n",
            "2409\n",
            "2410\n",
            "2411\n",
            "2412\n",
            "2413\n",
            "2414\n",
            "2415\n",
            "2416\n",
            "2417\n",
            "2418\n",
            "2419\n",
            "2420\n",
            "2421\n",
            "2422\n",
            "2423\n",
            "2424\n",
            "2425\n",
            "2426\n",
            "2427\n",
            "2428\n",
            "2429\n",
            "2430\n",
            "2431\n",
            "2432\n",
            "2433\n",
            "2434\n",
            "2435\n",
            "2436\n",
            "2437\n",
            "2438\n",
            "2439\n"
          ]
        }
      ],
      "source": [
        "ids = getIds(CARRIER, id_start=900)\n",
        "for el in ids:\n",
        "  print(el)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XNNsUVIh7fgR",
        "h3ke8rbkRUy0",
        "ts9SxkeDRY6o",
        "k2tzAYak7idO"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}