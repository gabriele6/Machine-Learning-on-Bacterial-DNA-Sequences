{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"BASE_PATH = '/content/drive/MyDrive/Health/'\nDATASET_PATH = BASE_PATH + 'dataset/'\nVOCAB_PATH = '/content/drive/MyDrive/Health/vocab.txt'\n\nTEST_SET_PATH = BASE_PATH + 'test_1000-1099.fas'\n\nURL_DRIVE = 'https://drive.google.com/uc?id='\n\n# BASIC DATASET\n# G_TRAIN_FILE = URL_DRIVE + '1-1eXBY8yHHmWDlzr-gZXAX8POor-P1xs'\n# G_DEV_FILE   = URL_DRIVE + '1bo_JKi6SbcRH8l-2GhIcdl1AnWvNaOYK'\n# G_TEST_FILE  = URL_DRIVE + '1-2zqIzM3FgsfTi4jJmC2wBb9KHjKk_xx'\n\n# K512 DATASET\nG_TRAIN_FILE = URL_DRIVE + '1-ESFbZab0N7npe1Q01549CqEKLfQoCDd'\nG_VALID_FILE   = URL_DRIVE + '1-GSyPyObFCwFqa8amuizDIQbE51sPAKw'\nG_TEST_FILE  = URL_DRIVE + '1-8EQbga_UpaV3wwBxuUc7dzij_LJzQ3a'\n\n# K67100 DATASET\n# G_TRAIN_FILE = URL_DRIVE + '1-1slsqddGwmcKNkj2b67Sg7xJvPjh5zI'\n# G_VALID_FILE   = URL_DRIVE + '1-DPawqObrh3rRCtl8gjlJJhyUm99k4mU'\n# G_TEST_FILE  = URL_DRIVE + '1-EV62T1oc5WSWjCBh1poGM2-2EGzgUnP'\n\nTRAIN_FILE = 'dataset/train/train.tsv'\nVALID_FILE = 'dataset/train/dev.tsv'\nTEST_FILE = 'dataset/test/dev.tsv'\n\n# ID_LABELS_K512\nTRAIN_ID_LABELS = URL_DRIVE + '1_D-b0-R4ybQUqzjA8rHxjvNQxBF36V-G'\nVALID_ID_LABELS = URL_DRIVE + '1-P13Uomv9SeBQondNdqNIKsYgWVkpbrj'\nTEST_ID_LABELS = URL_DRIVE + '1SRO5FxufHQcjGHFTXHuXy-M_xDAkqUWm'\n\n# ID_LABELS_K67100\n# TRAIN_ID_LABELS = URL_DRIVE + '1-LpjEfcq2mx9lX2H_5eCnEn-oVhGX3Ou'\n# VALID_ID_LABELS = URL_DRIVE + '1-O_aT-5332WSFqM2RhF9td1w__G6Zvk6'\n# TEST_ID_LABELS = URL_DRIVE + '1-NAPO59OR1Fv6dtpmxw1N6MBTlwLe6YF'\n\nTRAIN_ID_LABELS_FILE = 'dataset/train/train_id_labels.txt'\nVALID_ID_LABELS_FILE = 'dataset/train/dev_id_labels.txt'\nTEST_ID_LABELS_FILE = 'dataset/test/dev_id_labels.txt'\n\n# EMBEDDINGS K512\nEMB_TRAIN = URL_DRIVE + '1M6UwhFW9UZuCMAcz-vhtuABekM2f7o1m'\nEMB_VALID = URL_DRIVE + '1k6bDa1iIWVLfROKvuhvUBrrwhF4KBCxN'\nEMB_TEST = URL_DRIVE + '1XDjg9IStdPRHyh7wuVwHiN_mMwQdILeI'\n\nEMB_TRAIN_FILE = 'embeddings/train/'\nEMB_VALID_FILE = 'embeddings/valid/'\nEMB_TEST_FILE = 'embeddings/test/'\n\nK = 6\nSPLIT_SIZE = 3584 #512 sequences","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:45:08.467644Z","iopub.execute_input":"2022-09-01T10:45:08.467994Z","iopub.status.idle":"2022-09-01T10:45:08.481471Z","shell.execute_reply.started":"2022-09-01T10:45:08.467939Z","shell.execute_reply":"2022-09-01T10:45:08.480090Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Install","metadata":{}},{"cell_type":"code","source":"import os.path\nfrom IPython.core.display import HTML\n\nRESTART_FILE = 'restart.txt'\n\nif not os.path.exists(RESTART_FILE):\n    !pip -q install gdown\n    !pip -q install Bio\n\n    !git clone https://github.com/jerryji1993/DNABERT\n    %cd DNABERT\n    !pip install --editable .\n    %cd examples\n    !pip install -r requirements.txt\n    !touch $RESTART_FILE\n    HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"from Bio import SeqIO\nfrom itertools import product\nimport random\nimport glob\nimport os\nimport time\nimport shutil\n\nimport gdown\n\nimport torch\nfrom transformers import BertModel, BertConfig, DNATokenizer\n\nfrom sklearn.decomposition import PCA","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:45:10.945752Z","iopub.execute_input":"2022-09-01T10:45:10.946343Z","iopub.status.idle":"2022-09-01T10:45:19.295933Z","shell.execute_reply.started":"2022-09-01T10:45:10.946302Z","shell.execute_reply":"2022-09-01T10:45:19.295091Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"os.makedirs('dataset', exist_ok=True)\nos.makedirs('dataset/train', exist_ok=True)\nos.makedirs('dataset/test', exist_ok=True)\nos.makedirs('output', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:46:44.982901Z","iopub.execute_input":"2022-09-01T10:46:44.983483Z","iopub.status.idle":"2022-09-01T10:46:44.989320Z","shell.execute_reply.started":"2022-09-01T10:46:44.983442Z","shell.execute_reply":"2022-09-01T10:46:44.988409Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# downloading dataset seq-id\ngdown.download(G_TRAIN_FILE, TRAIN_FILE, quiet=False)\ngdown.download(G_VALID_FILE, VALID_FILE, quiet=False)\ngdown.download(G_TEST_FILE, TEST_FILE, quiet=False)\n\n# downloading dataset id-label\ngdown.download(TRAIN_ID_LABELS, TRAIN_ID_LABELS_FILE, quiet=False)\ngdown.download(VALID_ID_LABELS, VALID_ID_LABELS_FILE, quiet=False)\ngdown.download(TEST_ID_LABELS, TEST_ID_LABELS_FILE, quiet=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls dataset/train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -r dataset/*\n# !rm -r test/*\n\n# !rm -r output/*\n# !rm -r prediction/*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# filenames = ['train.tsv', 'dev.tsv', 'test.tsv']\n\n# def splitSeq2Lines(seq, split_size):\n#     with open('temp/' + filename, 'r') as f:\n#         with open('dataset/' + filename, 'w') as out:\n#             print(filename)\n            \n#             line = f.readline()\n#             out.write(line) # writing header\n#             ctr = 0\n#             while line:\n#                 # do stuff with line\n#                 line = f.readline()\n#                 start_pos = 0\n#                 end_pos = split_size\n#                 line = line.split('\\t')\n#                 while(start_pos<=len(line[0])):\n#                     out.write(line[0][start_pos:end_pos] + '\\t' + str(ctr) + '\\n')\n#                     start_pos+=split_size\n#                     end_pos+=split_size\n#                 ctr += 1\n    \n\n# def splitSequence(filename, split_size=SPLIT_SIZE):\n#     with open('temp/' + filename, 'r') as f:\n#         with open('dataset/' + filename, 'w') as out:\n#             print(filename)\n#             lines = f.readlines()\n#             out.write(lines[0])\n#             lines = lines[1:]\n#             random.shuffle(lines)\n#             ctr = 0\n#             for line in lines:\n#                 if ctr != len(lines) - 1:\n#                     line = line.split('\\t')\n#                     out.write(line[0][0:split_size] + '\\t' + line[1])\n#                 else:\n#                     line = line.split('\\t')\n#                     out.write(line[0][0:split_size] + '\\t' + line[1].split('\\n')[0])\n#                 ctr += 1\n\n# # SPLIT_SIZE = 671\n# print('Split Size: ' + str(SPLIT_SIZE))\n# for filename in filenames:\n#     splitSeq2Lines(filename, SPLIT_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finetuning","metadata":{}},{"cell_type":"code","source":"# using old dataset uploaded in kaggle/meningitis\n#!cp -r ../input/menigitis/dataset_67100/ ./\n# removing old runs of the model\n#!rm dataset_67100/train/cached_*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls dataset/train\n!ls dataset/test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(r'dataset_67100_shuffled/train/dev.tsv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #trying to shuffle the dev set\n# import random\n\n# os.makedirs('dataset_67100_shuffled', exist_ok=True)\n# os.makedirs('dataset_67100_shuffled/train', exist_ok=True)\n# os.makedirs('dataset_67100_shuffled/test', exist_ok=True)\n\n# with open('dataset_67100/train/train.tsv', 'r') as input:\n#     with open('dataset_67100_shuffled/train/train.tsv', 'w') as output:\n#         line = input.readline()\n#         output.write(line)\n#         data = []\n#         while line:\n#             line = input.readline()\n#             data.append(line)\n#         random.shuffle(data)\n#         print('Shuffled ' + str(len(data)) + ' sequences')\n#         for l in data:\n#             output.write(l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KMER = K\nMODEL_PATH='../input/menigitis/DNABERT6'\nDATA_PATH='dataset/train/'\n#DATA_PATH = 'dataset_67100/train/'\nOUTPUT_PATH='output'\n\nEPOCHS = 2.0\nMAX_SEQ_LENGTH = 256\nBATCH_SIZE = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    !python DNABERT/examples/run_finetune.py \\\n        --model_type dnalong \\\n        --tokenizer_name=dna$KMER \\\n        --model_name_or_path $MODEL_PATH \\\n        --task_name dnaprom \\\n        --do_train \\\n        --do_eval \\\n        --data_dir $DATA_PATH \\\n        --max_seq_length $MAX_SEQ_LENGTH \\\n        --per_gpu_eval_batch_size=$BATCH_SIZE   \\\n        --per_gpu_train_batch_size=$BATCH_SIZE   \\\n        --learning_rate 2e-4 \\\n        --num_train_epochs $EPOCHS \\\n        --output_dir $OUTPUT_PATH \\\n        --evaluate_during_training \\\n        --logging_steps 100 \\\n        --save_steps 4000 \\\n        --warmup_percent 0.1 \\\n        --hidden_dropout_prob 0.1 \\\n        --overwrite_output \\\n        --weight_decay 0.01 \\\n        --n_process 12","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!more output/eval_results.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 05/03/2022 11:28:33 - INFO - __main__ -   ***** Eval results  *****\n# 05/03/2022 11:28:33 - INFO - __main__ -     acc = 0.9833333333333333\n# 05/03/2022 11:28:33 - INFO - __main__ -     auc = 0.9916666666666666\n# 05/03/2022 11:28:33 - INFO - __main__ -     f1 = 0.983328702417338\n# 05/03/2022 11:28:33 - INFO - __main__ -     mcc = 0.9672041516493516\n# 05/03/2022 11:28:33 - INFO - __main__ -     precision = 0.9838709677419355\n# 05/03/2022 11:28:33 - INFO - __main__ -     recall = 0.9833333333333334","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !more output/eval_results.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = np.loadtxt(\"output/eval_results.txt\")\nprint(probs.shape)\nprobs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# val_output = 'output/eval_results.txt'\n# # probs = np.load('prediction/pred_results.npy')\n# probs = np.loadtxt(val_output)\n# # preds = np.argmax(probs)\n# preds = []\n# for prob in probs:\n#     if prob > 0.5:\n#         preds.append(1)\n#     else:\n#         preds.append(0)\n# print(len(preds))\n# print(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"KMER = K\nMODEL_PATH='output'\n# DATA_PATH='test'\nDATA_PATH = 'dataset_67100/test'\nPREDICTION_PATH='prediction'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python DNABERT/examples/run_finetune.py \\\n    --model_type dna \\\n    --tokenizer_name=dna$KMER \\\n    --model_name_or_path $MODEL_PATH \\\n    --task_name dnaprom \\\n    --do_predict \\\n    --data_dir $DATA_PATH  \\\n    --max_seq_length 512 \\\n    --per_gpu_pred_batch_size=6   \\\n    --output_dir $MODEL_PATH \\\n    --predict_dir $PREDICTION_PATH \\\n    --n_process 12","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probs = np.load('prediction/pred_results.npy')\nprint(probs.shape)\nprint(probs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nprobs = np.load('prediction/pred_results.npy')\n#probs = np.loadtxt(val_output)\n# preds = np.argmax(probs)\npreds = []\nfor prob in probs:\n    if prob > 0.5:\n        preds.append(1)\n    else:\n        preds.append(0)\nprint(len(preds))\nprint(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls dataset_67100/test/dev.tsv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntest_file = pd.read_csv('dataset_67100/test/dev.tsv', delimiter='\\t')\ntest_file['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove cache","metadata":{}},{"cell_type":"code","source":"# !rm -r test/cached*\n# !rm -r dataset/cached*","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encodings","metadata":{}},{"cell_type":"code","source":"MODEL_PATH = '../input/menigitis/DNABERT6'\nconfig = BertConfig.from_pretrained('https://raw.githubusercontent.com/jerryji1993/DNABERT/master/src/transformers/dnabert-config/bert-config-6/config.json')\ntokenizer = DNATokenizer.from_pretrained('dna6')\n    \ndef loadModel(model_path):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    model = BertModel.from_pretrained(model_path, config=config).to(device)\n    return model\n\ndef getEmbeddings(model, sequence):\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model_input = tokenizer.encode_plus(sequence, add_special_tokens=True, max_length=256)[\"input_ids\"]\n    model_input = torch.tensor(model_input, dtype=torch.long).to(device)\n    model_input = model_input.unsqueeze(0)   # to generate a fake batch with batch size one\n\n    output = model(model_input)\n    return output[1][0].detach()\n\ndef get_number(number):\n    return format(number, '04d')\n\ndef count_lines(filename):\n    f = open(filename)                  \n    lines = 0\n    buf_size = 1024 * 1024\n    read_f = f.read # loop optimization\n\n    buf = read_f(buf_size)\n    while buf:\n        lines += buf.count('\\n')\n        buf = read_f(buf_size)\n\n    return lines\n\ndef limit_decimals(number, decimals=2):\n    return format(number, '.'+str(decimals)+'f')\n\ndef writeEmbeddings(input_file, output_path='embeddings', start_id=0, limit=100):\n    start_time = time.time()\n    if 'train.tsv' in input_file: f_type = 'train'\n    elif '/train/dev.tsv' in input_file: f_type = 'valid'\n    else: f_type = 'test'\n    output_path = output_path + '/' + f_type + '/emb_seq'\n    n_lines = count_lines(input_file)\n    print('[' + input_file.split('/')[-2] + '] N_LINES: ' + str(n_lines))\n    \n    with open(input_file, 'r') as f_in:\n        ctr = 0\n        line = f_in.readline()\n        current_id = start_id\n        n_inserts = 0\n        temp_dict={}\n        while line:\n            line = f_in.readline()\n            splitted_line = line.split('\\t')\n            if len(splitted_line) < 2:\n                torch.save(temp_dict, output_path + get_number(current_id) + '.pt')\n                break\n            seq = splitted_line[0]\n            seq_id = int(splitted_line[1])\n            if seq_id < start_id:\n                ctr += 1\n                continue\n            emb = getEmbeddings(model, seq)\n            if current_id == seq_id:\n                # inserisci nel dizionario\n                temp_dict[n_inserts] = emb\n                n_inserts += 1\n            else:\n                # scrivi su file il dizionario\n                torch.save(temp_dict, output_path + get_number(current_id) + '.pt')\n                # aumenta current_id <- seq_id\n                current_id = seq_id\n                if current_id - start_id >= limit: # ==\n                    break\n                # svuota dizionario e inserisci la sequenza\n                n_inserts = 0\n                temp_dict = {}\n                temp_dict[n_inserts] = emb\n                \n\n            ctr += 1\n            if ctr % 100 == 0:\n                percentage = limit_decimals(ctr/n_lines*100)\n                elapsed_time = limit_decimals(time.time() - start_time)\n                print(percentage + \"% (\" + str(current_id) + \") --- \" + elapsed_time + \" seconds ---\")\n#             if (current_id - start_id) % 100 == 0:\n                \n        print(ctr)\n    \n\nmodel = loadModel(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:45:19.297916Z","iopub.execute_input":"2022-09-01T10:45:19.298190Z","iopub.status.idle":"2022-09-01T10:45:30.812013Z","shell.execute_reply.started":"2022-09-01T10:45:19.298154Z","shell.execute_reply":"2022-09-01T10:45:30.811236Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!rm -r embeddings/*\n\nos.makedirs('embeddings', exist_ok=True)\nos.makedirs('embeddings/train', exist_ok=True)\nos.makedirs('embeddings/valid', exist_ok=True)\nos.makedirs('embeddings/test', exist_ok=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"START_ID = 907\nLIMIT = 100\nwriteEmbeddings(TRAIN_FILE, output_path='embeddings', start_id=START_ID, limit=LIMIT)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n#emb_path = \"embeddings/train_id\"+str(START_ID)+\"_to\"+str(START_ID+LIMIT)\nemb_path = \"embeddings/train\"\nshutil.make_archive(emb_path, 'zip', emb_path)\nFileLink(r'embeddings/train.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls embeddings/train/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embe01 = torch.load('embeddings/train/emb_seq0000.pt')\nprint(len(embe01))\n\nembe02 = torch.load('embeddings/train/emb_seq0293.pt')\nprint(len(embe02))\n\nprint(embe01[0][0])\nprint(embe02[0][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Embeddings visualization\nhttps://krishansubudhi.github.io/deeplearning/2020/08/27/bert-embeddings-visualization.html  \nhttps://www.tensorflow.org/tensorboard/tensorboard_projector_plugin  \nhttps://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html","metadata":{}},{"cell_type":"code","source":"os.makedirs('embeddings', exist_ok=True)\ngdown.download(EMB_TRAIN, EMB_TRAIN_FILE, quiet=False)\nEMB_TRAIN_ZIP = EMB_TRAIN_FILE + 'train.zip'\n!unzip -q $EMB_TRAIN_ZIP \n!mv *.pt ./embeddings/train","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:45:30.814044Z","iopub.execute_input":"2022-09-01T10:45:30.814342Z","iopub.status.idle":"2022-09-01T10:45:42.177835Z","shell.execute_reply.started":"2022-09-01T10:45:30.814303Z","shell.execute_reply":"2022-09-01T10:45:42.176769Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!ls embeddings/train","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:45:42.179848Z","iopub.execute_input":"2022-09-01T10:45:42.180132Z","iopub.status.idle":"2022-09-01T10:45:43.481198Z","shell.execute_reply.started":"2022-09-01T10:45:42.180102Z","shell.execute_reply":"2022-09-01T10:45:43.480264Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import glob\nimport torch\n\ndef load_id_labels(path):\n  labels = []\n  with open(path, 'r') as input:\n    line = input.readline()\n    while line:\n      line = input.readline()\n      splitted_line = line.split('\\t')\n      if len(splitted_line) < 2:\n        break\n      seq_id = splitted_line[0]\n      label = int(splitted_line[1])\n      labels.append(label)\n\n  return labels\n\ndef getEmbeddingDataset(path):\n  embeddings = {}\n  emb_array = []\n  for filename in sorted(glob.glob(path + '/*.pt')):\n    seq_id = int(filename.split('.pt')[0].split('seq')[1])\n    if seq_id == len(labels): # erase the last one since it's empty\n      break\n    label = labels[seq_id]\n    #print('SeqID:' + str(seq_id) + ' -> label = ' + str(label))\n    tensors = torch.load(filename, map_location=torch.device('cpu'))\n    embeddings[seq_id] = {'label': label, \n                          'tensors': tensors\n                          }\n    emb_array.append(tensors)\n  return embeddings, emb_array\n  # print('seq[' + str(seq_id) + '] label = ' + str(label))s(TRAIN_ID_LABELS_FILE)\n#print(len(train_labels))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:46:53.591570Z","iopub.execute_input":"2022-09-01T10:46:53.592302Z","iopub.status.idle":"2022-09-01T10:46:53.600528Z","shell.execute_reply.started":"2022-09-01T10:46:53.592261Z","shell.execute_reply":"2022-09-01T10:46:53.599508Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# downloading dataset id-label\ngdown.download(TRAIN_ID_LABELS, TRAIN_ID_LABELS_FILE, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:46:56.002935Z","iopub.execute_input":"2022-09-01T10:46:56.003228Z","iopub.status.idle":"2022-09-01T10:46:57.273914Z","shell.execute_reply.started":"2022-09-01T10:46:56.003195Z","shell.execute_reply":"2022-09-01T10:46:57.273096Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"labels = load_id_labels(TRAIN_ID_LABELS_FILE)\nn_mening = sum(labels)\nprint('Total train_ids: ' + str(len(labels)))\nprint('Carrier/Disease: ' + str(len(labels)-n_mening) + '/' + str(n_mening))\n\nembeddings, emb_array = getEmbeddingDataset('embeddings/train')","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:46:59.449367Z","iopub.execute_input":"2022-09-01T10:46:59.449644Z","iopub.status.idle":"2022-09-01T10:47:06.566073Z","shell.execute_reply.started":"2022-09-01T10:46:59.449613Z","shell.execute_reply":"2022-09-01T10:47:06.565251Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"labels[707]","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:47:11.937128Z","iopub.execute_input":"2022-09-01T10:47:11.937795Z","iopub.status.idle":"2022-09-01T10:47:11.943970Z","shell.execute_reply.started":"2022-09-01T10:47:11.937756Z","shell.execute_reply":"2022-09-01T10:47:11.943104Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(len(embeddings[0]['tensors']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_X = []\n# train_y = []\n\n# for key in embeddings:\n#   label = embeddings[key]['label']\n#   for emb in embeddings[key]['tensors']:\n#     emb = embeddings[key]['tensors'][emb]\n#     train_X.append(emb.tolist())\n#     train_y.append(label)\n\n# import pandas as pd\n# df = pd.DataFrame(list(zip(train_X, train_y)),\n#                columns =['X', 'y'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = []\nemb_labels = []\nemb_seq_ids = []\nfor emb_file in sorted(glob.glob('embeddings/train/*.pt')):\n    # embeddings/train/emb_seq0041.pt\n    seq_id = int(emb_file.split('emb_seq')[-1].split('.pt')[0])\n    seq_emb = torch.load(emb_file)\n    for j in seq_emb:\n        embeddings.append(seq_emb[j].cpu().numpy())\n        emb_labels.append(labels[seq_id])\n        emb_seq_ids.append(seq_id)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:48:24.229653Z","iopub.execute_input":"2022-09-01T10:48:24.229952Z","iopub.status.idle":"2022-09-01T10:48:45.773380Z","shell.execute_reply.started":"2022-09-01T10:48:24.229919Z","shell.execute_reply":"2022-09-01T10:48:45.772549Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"len(emb_labels)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:48:45.775156Z","iopub.execute_input":"2022-09-01T10:48:45.775613Z","iopub.status.idle":"2022-09-01T10:48:45.783123Z","shell.execute_reply.started":"2022-09-01T10:48:45.775572Z","shell.execute_reply":"2022-09-01T10:48:45.782147Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components=3)\npca_values = pca.fit_transform(embeddings)\npca_values.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:48:56.088643Z","iopub.execute_input":"2022-09-01T10:48:56.088986Z","iopub.status.idle":"2022-09-01T10:49:10.587038Z","shell.execute_reply.started":"2022-09-01T10:48:56.088948Z","shell.execute_reply":"2022-09-01T10:49:10.586290Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ncolumn_values = ['X', 'Y', 'Z']\ndf = pd.DataFrame(data = pca_values, columns=column_values)\ndf['seq_id'] = emb_seq_ids\ndf['label'] = emb_labels\ndf","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:49:10.588707Z","iopub.execute_input":"2022-09-01T10:49:10.589501Z","iopub.status.idle":"2022-09-01T10:49:10.772397Z","shell.execute_reply.started":"2022-09-01T10:49:10.589464Z","shell.execute_reply":"2022-09-01T10:49:10.771422Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df[df['seq_id']==715]","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:58:36.751057Z","iopub.execute_input":"2022-09-01T10:58:36.751400Z","iopub.status.idle":"2022-09-01T10:58:36.763549Z","shell.execute_reply.started":"2022-09-01T10:58:36.751361Z","shell.execute_reply":"2022-09-01T10:58:36.762264Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"y = df[df.columns[-1:]]\nX = df[df.columns[:-2]]\n\nX = X.values\ny = y.values\n\nprint('X: ({},{})'.format(X.shape[0], X.shape[1]))\nprint('y: ({},{})'.format(y.shape[0], y.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:49:30.404667Z","iopub.execute_input":"2022-09-01T10:49:30.405174Z","iopub.status.idle":"2022-09-01T10:49:30.425564Z","shell.execute_reply.started":"2022-09-01T10:49:30.405126Z","shell.execute_reply":"2022-09-01T10:49:30.424774Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# scaler = StandardScaler()\n# scaler = scaler.fit(X)\n\ntr_X, ts_X, tr_y, ts_y = train_test_split(X, y, test_size=0.2, random_state=1)\ntr_y = tr_y.ravel()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:49:33.716530Z","iopub.execute_input":"2022-09-01T10:49:33.716798Z","iopub.status.idle":"2022-09-01T10:49:33.739720Z","shell.execute_reply.started":"2022-09-01T10:49:33.716767Z","shell.execute_reply":"2022-09-01T10:49:33.739013Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import KFold\n\nrfc = RandomForestClassifier()\nrfc.fit(tr_X,tr_y)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:49:45.509509Z","iopub.execute_input":"2022-09-01T10:49:45.509799Z","iopub.status.idle":"2022-09-01T10:50:22.991604Z","shell.execute_reply.started":"2022-09-01T10:49:45.509768Z","shell.execute_reply":"2022-09-01T10:50:22.990861Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# predictions\nrfc_predict = rfc.predict(ts_X)\nrfc_cv_score = cross_val_score(rfc, tr_X, tr_y, cv=4, scoring='roc_auc')\n\nprint(\"=== Confusion Matrix ===\")\nprint(confusion_matrix(ts_y, rfc_predict))\nprint('\\n')\nprint(\"=== Classification Report ===\")\nprint(classification_report(ts_y, rfc_predict))\nprint('\\n')\nprint(\"=== All AUC Scores ===\")\nprint(rfc_cv_score)\nprint('\\n')\nprint(\"=== Mean AUC Score ===\")\nprint(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:50:37.200410Z","iopub.execute_input":"2022-09-01T10:50:37.200694Z","iopub.status.idle":"2022-09-01T10:52:25.904706Z","shell.execute_reply.started":"2022-09-01T10:50:37.200663Z","shell.execute_reply":"2022-09-01T10:52:25.903688Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"values = pd.DataFrame(df['seq_id'].value_counts()).sort_values(by=['seq_id'], ascending=False)\nvalues","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:52:25.907119Z","iopub.execute_input":"2022-09-01T10:52:25.907471Z","iopub.status.idle":"2022-09-01T10:52:25.923504Z","shell.execute_reply.started":"2022-09-01T10:52:25.907431Z","shell.execute_reply":"2022-09-01T10:52:25.922689Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n\ndef project_embeddings_3d(df, x, y, z, color):\n    df_copy = df.copy()\n    df_copy[\"label\"] = df[\"label\"].astype(str)\n    fig = px.scatter_3d(df_copy, x=x, y=y, z=z, color=color)\n    fig.update_traces(marker=dict(size=3),\n                  selector=dict(mode='markers'))\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:55:43.381998Z","iopub.execute_input":"2022-09-01T10:55:43.382752Z","iopub.status.idle":"2022-09-01T10:55:45.258686Z","shell.execute_reply.started":"2022-09-01T10:55:43.382714Z","shell.execute_reply":"2022-09-01T10:55:45.257940Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def plot2DSeq(id, df=df, axes=['X', 'Y']):\n    seq = df[df['seq_id'] == id]\n    px.scatter(seq, x=axes[0], y=axes[1], color='label')\n    \ndef plotSeq(id, df=df):\n    seq = df[df['seq_id'] == id]\n    project_embeddings_3d(seq, x='X', y='Y', z='Z', color='label')\n    \ndef plotCompare(ids, df=df):\n    seq = df[df[\"seq_id\"].isin(ids)]\n    project_embeddings_3d(seq, x='X', y='Y', z='Z', color='label')","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:55:45.517879Z","iopub.execute_input":"2022-09-01T10:55:45.518446Z","iopub.status.idle":"2022-09-01T10:55:45.526629Z","shell.execute_reply.started":"2022-09-01T10:55:45.518400Z","shell.execute_reply":"2022-09-01T10:55:45.525919Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"labels[715]","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:57:36.865877Z","iopub.execute_input":"2022-09-01T10:57:36.866377Z","iopub.status.idle":"2022-09-01T10:57:36.876959Z","shell.execute_reply.started":"2022-09-01T10:57:36.866327Z","shell.execute_reply":"2022-09-01T10:57:36.876231Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#plotSeq(293)\n#plotSeq(715)\n\nnumbers = [293, 715]\n#numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 707, 708, 709, 710, 711, 712, 713, 714]\nplotCompare(numbers)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:57:17.741196Z","iopub.execute_input":"2022-09-01T10:57:17.741984Z","iopub.status.idle":"2022-09-01T10:57:17.824998Z","shell.execute_reply.started":"2022-09-01T10:57:17.741935Z","shell.execute_reply":"2022-09-01T10:57:17.823943Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"numbers = [0, 293, 715]\nseq = df[df[\"seq_id\"].isin(numbers)]\npx.scatter(seq, x='X', y='Y', color='label')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification on Embeddings (Random Forest)","metadata":{}},{"cell_type":"code","source":"# import tensorflow.keras.backend as K\n# from sklearn.model_selection import RandomizedSearchCV\n# from sklearn.ensemble import RandomForestClassifier\n\n# from sklearn.model_selection import KFold\n\n\n# forest = RandomForestClassifier()\n# rf_random = RandomizedSearchCV(estimator = forest, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n# rf_random.fit(train_X, train_y)\n","metadata":{},"execution_count":null,"outputs":[]}]}